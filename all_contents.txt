     <meta charset="utf-8" emacsmode="-*- markdown -*-"><link rel="stylesheet" href="https://casual-effects.com/markdeep/latest/slate.css?">

                        **Slate Template**
                           Version 1.23


This template is good for "dark mode" documentation. It automatically
switches to black-on-white and an inline table of contents when
printed.


Initialization
==============================================================

Itaque earum rerum hic tenetur a sapiente delectus, ut aut reiciendis
voluptatibus maiores alias consequatur aut perferendis doloribus
asperiores repellat.

Asset Based
--------------------------------------------------------------

Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do
eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad
minim veniam, quis nostrud exercitation ullamco laboris nisi ut
aliquip ex ea commodo consequat. Duis aute irure dolor in
reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla
pariatur.

 Maine | Iowa | Colorado
-------|------|----------
   1   |  4   |   10
  ME   |  IA  |   CO
 Blue  | Red  | Brown
[Table [states]: Caption with label.]


### Exporters

Excepteur sint occaecat cupidatat non proident, sunt in
culpa qui officia deserunt mollit anim id est laborum:

- Incididunt
- Bonus Unum
- Quibusdam

```````````````````````````````````````````````
count_lines () {
  local f=$1
  local m
  m=`wc -l $f | sed 's/^\([0-9]*\).*$/\1/'`
  return $m
}
```````````````````````````````````````````````


Procedural
--------------------------------------------------------------

At vero eos et accusamus et iusto odio dignissimos ducimus qui
blanditiis praesentium voluptatum deleniti atque corrupti quos dolores
et quas molestias excepturi sint occaecati cupiditate non provident,
similique sunt in culpa qui officia deserunt mollitia animi, id est
laborum et dolorum fuga. Et harum quidem rerum facilis est et expedita
distinctio.

**************************************************************
*
* .---.       .-.        .-.       .-.
* | A +----->| 1 +<---->| 2 |<----+ 4 +------------------.
* '---'       '-'        '+'       '-'                    |
*                         |         ^                     |
*                         v         |                     v
*                        .-.      .-+-.        .-.      .-+-.
*                       | 3 +---->| B |<----->| 5 +---->| C |
*                        '-'      '---'        '-'      '---'
**************************************************************

Nam libero tempore, cum `soluta` nobis est eligendi optio
cumque nihil impedit quo minus id quod maxime placeat facere possimus,
omnis voluptas assumenda est, omnis dolor repellendus. Temporibus
autem quibusdam et aut officiis debitis aut rerum necessitatibus saepe
eveniet ut et voluptates repudiandae sint et molestiae non
recusandae.

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
a long preformatted code block a long preformatted code block a long preformatted code block a long preformatted code block a long preformatted code block
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~



Modules
==============================================================

Nam libero tempore, cum soluta nobis est eligendi optio
cumque nihil impedit quo minus id quod maxime placeat facere possimus,
omnis voluptas assumenda est, omnis dolor repellendus.


~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ rust
fn main() {
    let x = 5u32;

    let y = {
        let x_squared = x * x;
        let x_cube = x_squared * x;

        // This expression will be assigned to `y`
        x_cube + x_squared + x
    };

    let z = {
        // The semicolon suppresses this expression and `()` is assigned to `z`
        2 * x;
    };

    println!("x is {:?}", x);
    println!("y is {:?}", y);
    println!("z is {:?}", z);
}
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

<!--
![`a long code caption a long code caption`](robot.jpg) ![`a long code caption`](robot.jpg) ![`a long code caption`](robot.jpg) ![`a long code caption`](robot.jpg)
![`a long code caption a long code caption`](robot.jpg) ![`a long code caption`](robot.jpg) ![`a long code caption`](robot.jpg) ![`a long code caption`](robot.jpg)
-->

See Also
==============================================================

[Link to nowhere](nowhere).



<style class="fallback">body{visibility:hidden}</style><script>markdeepOptions={tocStyle:'long'};</script>
<!-- Markdeep: --><script src="https://casual-effects.com/markdeep/latest/markdeep.min.js?" charset="utf-8"></script>
<meta charset="utf-8" emacsmode="-*- markdown -*-"><link rel="stylesheet" href="https://casual-effects.com/markdeep/latest/newsmag.css?">

    <meta name="author" content="Your Name">
    <meta name="description" content="newsmag description"
    <meta name="keywords" content="keyword1, keyword2, keyword3, keyword4, keyword5">

    <!-- Other common meta tags you might want to include -->
    <meta name="robots" content="index, follow">
    <meta name="language" content="English">

    <!-- Open Graph meta tags for better social media sharing -->
    <meta property="og:title" content="Your Page Title">
    <meta property="og:description" content="A brief description for social media sharing">
    <meta property="og:image" content="https://example.com/image.jpg">
    <meta property="og:url" content="https://example.com/page-url">

	<script src="https://morgan3d.github.io/include.js/include.min.js"></script>


                          **Jag.is**
	Cooperative Innovation Studio specialized in software development, devops and project management.
	We are on this for the long term with our members, our software and our customers.

We are a software development and Innovation Studio.
Specialized in high quality, long term maintenance of software products.


An independent research lab exploring the future of tools for thought.
================================================================

We envision a new computer that amplifies human intelligence. A system
that helps you think more clearly, collaborate more effectively, and is
available anywhere and anytime. Though the specifics of our work
continue to evolve, everything we do is in pursuit of this vision.

Research Tracks
---------------------------------------------------------------

Our research spans a wide variety of domains from theoretical computer
science to practical user experiences. We currently have three primary
research themes.

### Malleable Software

Designing software environments where people can customize tools in the
moment to meet their unique needs.

### Programmable Ink

Discovering a dynamic medium for sketching ideas where adding behaviors
and interaction is as natural as applying ink to paper.

### [Local-First](/local-first)

Exploring software architecture that returns data to users and enables
collaboration in every tool.


Our Writing
==============================================================

This are the innovations that have been ocupaying our minds lately

<ul>
  <li>[./projects](././projects/) 
      <ul>
  	  <li>[./projects/rewards.codes](././projects/rewards.codes/) 
  	  </li>
  	</ul>
      <ul>
  	  <li>[./projects/AOP_in_Eiffel](././projects/AOP_in_Eiffel/) 
  	  </li>
  	</ul>
  </li>
  <li>[./posts](././posts/) 
      <ul>
  	  <li>[./posts/ideas](././posts/ideas/) 
  	  </li>
  	</ul>
      <ul>
  	  <li>[./posts/how_to_define_a_problem](././posts/how_to_define_a_problem/) 
  	  </li>
  	</ul>
      <ul>
  	  <li>[./posts/faust_a_musical_dsl](././posts/faust_a_musical_dsl/) 
  	  </li>
  	</ul>
      <ul>
  	  <li>[./posts/a_dozen_problems](././posts/a_dozen_problems/) 
  	  </li>
  	</ul>
      <ul>
  	  <li>[./posts/Unlocking_the_Power_of_Personal_Cloud](././posts/Unlocking_the_Power_of_Personal_Cloud/) 
  	  </li>
  	</ul>
      <ul>
  	  <li>[./posts/Understanding_complexity_in_software_systems](././posts/Understanding_complexity_in_software_systems/) 
  	  </li>
  	</ul>
      <ul>
  	  <li>[./posts/The_Rise_and_Fall_of_Abacus_Rationale](././posts/The_Rise_and_Fall_of_Abacus_Rationale/) 
  	  </li>
  	</ul>
      <ul>
  	  <li>[./posts/Terravision_vs_Google_Earth](././posts/Terravision_vs_Google_Earth/) 
  	  </li>
  	</ul>
      <ul>
  	  <li>[./posts/Single_text_file](././posts/Single_text_file/) 
  	  </li>
  	</ul>
      <ul>
  	  <li>[./posts/Requirements_in_the_Age_of_AI](././posts/Requirements_in_the_Age_of_AI/) 
  	  </li>
  	</ul>
      <ul>
  	  <li>[./posts/Psychological_Safety](././posts/Psychological_Safety/) 
  	  </li>
  	</ul>
      <ul>
  	  <li>[./posts/PMI_vs_Flight_Levels_Less_is_More](././posts/PMI_vs_Flight_Levels_Less_is_More/) 
  	  </li>
  	</ul>
      <ul>
  	  <li>[./posts/Navigating_GHC_compilation_errors_in_Emacs](././posts/Navigating_GHC_compilation_errors_in_Emacs/) 
  	  </li>
  	</ul>
      <ul>
  	  <li>[./posts/Multi-layered_Proxy_Architecture_for_my_Personal_Cloud](././posts/Multi-layered_Proxy_Architecture_for_my_Personal_Cloud/) 
  	  </li>
  	</ul>
      <ul>
  	  <li>[./posts/Manage_complexity_behind_simple_interfaces](././posts/Manage_complexity_behind_simple_interfaces/) 
  	  </li>
  	</ul>
      <ul>
  	  <li>[./posts/Kanban_Serious_Games_Intro](././posts/Kanban_Serious_Games_Intro/) 
  	  </li>
  	</ul>
      <ul>
  	  <li>[./posts/Kanban_Case_Study_in_Public_Sector_Part_I](././posts/Kanban_Case_Study_in_Public_Sector_Part_I/) 
  	  </li>
  	</ul>
      <ul>
  	  <li>[./posts/Extending_the_Power_of_your_Personal_Cloud](././posts/Extending_the_Power_of_your_Personal_Cloud/) 
  	  </li>
  	</ul>
      <ul>
  	  <li>[./posts/Did_You_Read_This_Book](././posts/Did_You_Read_This_Book/) 
  	  </li>
  	</ul>
      <ul>
  	  <li>[./posts/Devtron_Enhancing_Kubernetes_Management_and_DevOps_Pipelines](././posts/Devtron_Enhancing_Kubernetes_Management_and_DevOps_Pipelines/) 
  	  </li>
  	</ul>
      <ul>
  	  <li>[./posts/Declarative_dotfiles_with_Home_Manager](././posts/Declarative_dotfiles_with_Home_Manager/) 
  	  </li>
  	</ul>
      <ul>
  	  <li>[./posts/Creating_a_QR_for_Google_review_URL](././posts/Creating_a_QR_for_Google_review_URL/) 
  	  </li>
  	</ul>
      <ul>
  	  <li>[./posts/Create_Abundance_With_Software](././posts/Create_Abundance_With_Software/) 
  	  </li>
  	</ul>
      <ul>
  	  <li>[./posts/Bloom_Taxonomy_Shu_Ha_Ri_Expertise](././posts/Bloom_Taxonomy_Shu_Ha_Ri_Expertise/) 
  	  </li>
  	</ul>
      <ul>
  	  <li>[./posts/A_Tool_in_a_World_Full_of_Distractions](././posts/A_Tool_in_a_World_Full_of_Distractions/) 
  	  </li>
  	</ul>
      <ul>
  	  <li>[./posts/A_Real_Challenge_as_DevOps_Navigating_Key_Hurdles_and_Solutions](././posts/A_Real_Challenge_as_DevOps_Navigating_Key_Hurdles_and_Solutions/) 
  	  </li>
  	</ul>
  </li>
  <li>[./about](././about/) 
  </li>
</ul>
--------------------------------------------------

#### Connect with us

Say [hello@jag.is](mailto://hello@jag.is)

Code on [Github](https://github.com/jagcoop)

#### Our news letter

Keep up-to-date with the lab's latest findings, appearances, and
happenings by subscribing to our newsletter. For a sneak peek, [browse
the archive](/newsletter).


<ul>
    <li><a href="/">index</a></li>
		<li>[./projects](/./projects/index.html)</li>
		<li>[./posts](/./posts/index.html)</li>
		<li>[./about](/./about/index.html)</li>
</ul>

<script src="https://casual-effects.com/markdeep/latest/markdeep.min.js?" charset="utf-8"></script>



Email

--------------------------------------------------


CC-By-Sa-NC JagIs

<style class="fallback">body{visibility:hidden}</style><script>markdeepOptions={tocStyle:'medium'};</script>
<!-- Markdeep: --><script src="https://casual-effects.com/markdeep/latest/markdeep.min.js?" charset="utf-8"></script>
<ul>
    <li><a href="/">index</a></li>
		<li>[./projects](/./projects/index.html)</li>
		<li>[./posts](/./posts/index.html)</li>
		<li>[./about](/./about/index.html)</li>
</ul>

<script src="https://casual-effects.com/markdeep/latest/markdeep.min.js?" charset="utf-8"></script>
<meta charset="utf-8" emacsmode="-*- markdown -*-">

# A Real Challenge as DevOps: Navigating Key Hurdles and Solutions

October 31th, 2024
by *Leonel Perea*

## Introduction

In today’s fast-paced software industry, DevOps teams are expected to deliver rapid, reliable, and secure deployments. However, the journey to optimized DevOps practices is laden with challenges. This article explores major obstacles commonly faced by DevOps professionals and presents solutions backed by industry insights from recent DevOps blogs.

## Key Challenges in DevOps

### Integrating Security from the Start (DevSecOps)

Security is increasingly recognized as a key DevOps responsibility. Integrating security measures directly into the development lifecycle—DevSecOps—ensures early vulnerability detection and reduces risks post-deployment. Blogs from AWS DevOps and Google Cloud highlight how security automation and integrated testing can secure code without disrupting the pipeline.

- **Challenge**: Many organizations struggle with integrating security checks without slowing down the CI/CD cycle.
- **Solution**: DevSecOps practices emphasize automated vulnerability scanning in code repositories and container images, ensuring that security remains an intrinsic, unobtrusive part of the pipeline.

### Managing Multi-Cloud and Hybrid Environments

Operating across multiple cloud platforms adds complexity to configuration management, orchestration, and monitoring. According to Azure DevOps blogs, having the right tools and workflows for these environments can streamline processes while maintaining visibility across platforms.

- **Challenge**: Each cloud provider has unique configurations and APIs, creating fragmented workflows.
- **Solution**: Using centralized tools for cross-platform management, such as HashiCorp’s Terraform for infrastructure as code, provides a consistent approach to managing resources across clouds.

### Automating and Streamlining CI/CD Pipelines

The demand for automated CI/CD pipelines is rising as organizations seek faster delivery cycles with minimal errors. GitHub’s DevOps blog emphasizes the need for automation tools and pipeline optimization to manage deployments at scale.

- **Challenge**: Achieving fully automated pipelines that support the pace of rapid deployments and rollback strategies without manual intervention.
- **Solution**: Implementing best-in-class CI/CD tools, like Jenkins or GitHub Actions, allows for scalable, automated testing and deployments. Additionally, using containerized environments with Docker or Kubernetes enables more consistent pipeline execution.

### Enhancing Observability and Monitoring

Observability is crucial for maintaining high availability in complex, distributed systems. Stack Overflow’s blog identifies observability as foundational for DevOps teams to quickly detect and address issues in production environments.

- **Challenge**: Ensuring comprehensive visibility across microservices, containers, and cloud services.
- **Solution**: Leveraging observability tools like Prometheus and Grafana, which integrate with Kubernetes, enables real-time monitoring. Additionally, implementing log aggregation and correlation tools aids in root-cause analysis.

### Infrastructure as Code (IaC) for Consistency

IaC simplifies infrastructure provisioning, making deployments repeatable and consistent. According to DevOpsCube, IaC tools like Terraform and Ansible support automated infrastructure scaling and help prevent configuration drift.

- **Challenge**: Balancing speed with accurate configuration in highly dynamic environments.
- **Solution**: Creating modular IaC code allows reusable components for infrastructure, improving consistency across environments. Regular testing of infrastructure scripts ensures reliability in deployment.

### Building a Collaborative DevOps Culture

Successful DevOps requires a cultural shift that promotes transparency, accountability, and cross-functional collaboration. Atlassian’s DevOps blog highlights how open communication and shared responsibilities can significantly enhance DevOps practices.

- **Challenge**: Breaking down silos between development, operations, and security teams.
- **Solution**: Introducing collaborative tools like Slack or Jira for real-time communication, and regular retrospectives to foster a continuous improvement mindset across teams.

## Conclusion

Overcoming the complexities of DevOps involves mastering a range of tools and practices while promoting a collaborative culture. By addressing these common challenges—DevSecOps integration, multi-cloud management, CI/CD automation, observability, IaC, and culture-building—DevOps teams can enhance efficiency, security, and scalability. As DevOps continues to evolve, staying informed on best practices and emerging tools is crucial for maintaining a resilient and responsive DevOps framework.

<style class="fallback">body{visibility:hidden}</style><script>markdeepOptions={tocStyle:'long'};</script>
<!-- Markdeep: --><script src="https://casual-effects.com/markdeep/latest/markdeep.min.js?" charset="utf-8"></script> <meta charset="utf-8" emacsmode="-*- markdown -*-">
# A Tool in a World Full of Distractions
September 21th, 2024
by *Karina Chaires*

In today's distraction-filled environment, having effective tools at our disposal is essential for maintaining focus and productivity.

A few months ago, I realized that I was struggling to concentrate and finish simple tasks that took me longer than they should have, even though they weren't "complicated." I was also distracted by things around me, like simply unlocking my phone to do a bank transaction or something else I deemed "important", and suddenly, 15 minutes or more would pass without me accomplishing anything. In the worst cases, I would forget what I intended to do.

In search of a solution to this "problem" I came across the recommendation for the book **"Deep Work: Rules for Focused Success in a Distracted World"** by Cal Newport. This book emphasizes the importance of deep work — the ability to focus without distraction on cognitively demanding tasks. Newport argues that in a world full of distractions, cultivating deep work is essential for achieving high levels of productivity and professional success.

The book is divided into two main parts: the concept of deep work and strategies to cultivate it.

## The concept of DeepWork

In the first part, Newport defines deep work as a state of concentration that enables individuals to produce high-quality work and develop valuable skills. He contrasts this with shallow work, which consists of non-cognitively demanding tasks often performed while distracted. Newport suggests that the ability to engage in deep work is becoming increasingly rare yet is highly valuable in today's economy, where knowledge work is key.

## Strategies to cultivate it.

Newport supports his arguments with examples from successful individuals who practice deep work, including authors, scientists, and entrepreneurs. He illustrates how their focus and commitment to deep work have led to significant contributions and achievements.

The second part of the book offers practical strategies for cultivating deep work in daily life. Newport outlines four essential rules:

1. **Work Deeply**: He stresses the importance of rituals and routines to enhance focus, suggesting techniques such as time blocking, setting clear goals, and removing distractions. Newport advocates for creating an environment that supports deep work.

2. **Embrace Boredom**: Newport argues that one must learn to accept boredom and resist the temptation to switch to shallow tasks. He encourages practicing concentration and developing the ability to focus over time, which involves training the mind to remain engaged with challenging tasks.

3. **Quit Social Media**: Newport critically examines the role of social media and other distractions, recommending that individuals assess the tools they use and eliminate those that do not provide significant benefits to their professional and personal lives.

4. **Drain the Shallows**: He advises minimizing the time spent on shallow work by scheduling every minute of the day. This practice helps prioritize deep work and ensures that time is not wasted on low-value activities.

## In my personal experience

For me, the first strategy has been helpful, and I've implemented it by keeping my phone away for certain periods. I'm trying to create a schedule for each activity throughout the day, although I haven't fully succeeded yet. I will continue to improve my concentration practices because, ultimately, **"Deep Work"** serves as both a manifesto for focused success and a practical guide for cultivating concentration in a world full of distractions. Newport's insights resonate with anyone seeking to enhance productivity, achieve professional goals, and develop valuable skills in an era dominated by superficial engagement.


<style class="fallback">body{visibility:hidden}</style><script>markdeepOptions={tocStyle:'long'};</script>
<!-- Markdeep: --><script src="https://casual-effects.com/markdeep/latest/markdeep.min.js?" charset="utf-8"></script>
 <meta charset="utf-8" emacsmode="-*- markdown -*-">
# Reflecting on developing expertise using Blooms Taxonomy, and Shu Ha Ri model
Octubre 25th, 2024
by *Pepe Hernandez*


## Bloom Taxonomy
Boom's taxonomy is a multitiered model of classified thinking according to six cognitive levels of complexity. Bloom and a group of educators created the taxonomy in 1958. 

In 1995, a group of specialists started. In 2001, the revisited Bloosm Taxonomy was published. 

```markdown
|                          |                             The Cognitive Process Dimension                            |
|--------------------------|------------------------------------|------------|---------------|----------|-----------|
| The Knowledge Dimension  | Remember              | Understand | Apply      | Analyze       | Evaluate | Create    |
|--------------------------|-----------------------|------------|------------|---------------|----------|-----------|
| Factual Knoledge         | List                  | Summarize  | Classify   | Order         | Rank     | Combine   |
| Conceptual Knowledge     | Describe              | Interpret  | Experiment | Explain       | Assess   | Plan      |
| Procedural Knowledge     | Tabualte              | Predict    | Calculate  | Differentiate | Conclude | Compose   |
| Meta-Cognitive Knowledge | Appropiate use        | Execute    | Construct  | Achieve       | Action   | Actualize |
```
Source: Oreng State University. 

The Bloom Taxonomy framework consists of six categories **each requiring achievement of the prior skill or ability before the next, more complex one, remains easy to understand.**

## Get directly to the superior levels of learning, a wrong assumption 

As a student, I believed that superior levels of taxonomy were what I had to focus. Critical thinking, for example, is prevalent among marketing messages today, and it was 20 years ago. I did believe that understanding and memorizing things was wrong. 

Even several Bloom's taxonomy promoters believe that superior levels of thinking are the proper focus for students and professionals. They are wrong, too.

Bloom's taxonomy is hierarchical. That means a specific pyramid level needs the student to master the previous ones.

## The Software Product Managemer Certified training is focused on the first two levels of learning

I am working on a Systematic Literature Review about Software Product Management and Artificial Intelligence. My base research question is, "Which approaches exist that allow software product managers to have expertise in specific Software Product Management Practices?" One of the first articles I found identifies different Product Management Frameworks. The ISPMA (International Software Product Management Association) is one of the most well-known. Several of the most well-known researchers of SPM (Ebert and Maglyas, among others) participated in developing the learning material for the Certified training.  

The educational objectives of the ISPMA syllabus for the Software Product Manager Certified course focus on two cognitive levels of knowledge: "know" and "understand," the two basic levels of the Bloom Taxonomy—the first Bloom Taxonomy, not the revised one.

The two verbs are placeholders. **Know** for enumerate, characterize, recognize, and name. **Understand** for reflect, analyze, execute, justify, describe, judge, display, design, develop, complete, explain, elucidate, elicit, formulate, identify, interpret, reason, translate, distinguish, compare, understand, suggest, and summarize.

My base question is how to develop expertise in Software Management Practices. The two basic levels were a previous requirement. The ISPMA learning objective is not intended, at least in this foundational training course, to develop expertise. It's part of the solution. 

## The Shu Ha Ri model is suitable for framing the expertise level from Apprentice to Master.

As I am looking for practices that allow me to develop expertise, I think the Shu Ha Ri model better explains what I am expecting.

The Shu Ha Ri is another learning model that comes from Japanese culture. It is the model of Master and apprentice. Shu means to obey. Here, the apprentice must do what the Master says. This is well represented in martial arts with the figure of katas. The apprentice knows the Kata and practices. When the student has enough practice, she becomes a practitioner. When the student dominates the Kata, she can introduce their variations to the movements. Ha point to this level of mastery. Ha means detach. When the apprentice dominates several katas, she creates her own. She designs, develops, and innovates. She became the Kata. 

## The following question. Are there AI tools to develop Software Product Manager expertise? 

What must a Producto Manager do to advance in these levels of learning and mastery? And what the existing tools are that allow them to become one. 

The way to start is with the basic level of knowledge (to know). How does a Product Manager know what she must know? 

The second step is to understand. How can a Product manager understand practices? Are there IA tools that allow them to understand? 

This will come in another story...

## References
https://cft.vanderbilt.edu/guides-sub-pages/blooms-taxonomy/



<style class="fallback">body{visibility:hidden}</style><script>markdeepOptions={tocStyle:'long'};</script>
<!-- Markdeep: --><script src="https://casual-effects.com/markdeep/latest/markdeep.min.js?" charset="utf-8"></script><meta charset="utf-8" emacsmode="-*- markdown -*-">

# 🌟 Create Abundance with Software 🌟
Nov 7th, 2024
by *Agus Rumayor*

We live in an age where abundance is within reach, yet scarcity persists—rooted in outdated, profit-driven systems. But what if we could break free from these limitations? What if we could build a world where resources are managed efficiently, equitably, and sustainably? This vision aligns with the principles of a Resource-Based Economy (RBE), as championed by Jacque Fresco, and software plays a key role in making it a reality.

## The Problem: Money-Oriented Constraints
* 💼 Healthcare: Systems prioritize profitability over universal access.
* 🏫 Education: Quality learning is treated as a commodity, leaving many behind.
* 🌱 Sustainability: Environmental priorities are often sacrificed for short-term economic gains.
* 📈 Business: Profit motives limit collaboration and long-term societal value.

These constraints are a consequence of the scarcity that our money-oriented society endures, perpetuating cycles of inequality and waste, but RBE offers a different approach: managing resources intelligently for the benefit of all, without relying on money as the main driver.

## Software as a Catalyst for Resource-Based Abundance
* 🔧 Automation: Liberating Human Potential
In an RBE, automation handles tasks that don’t require human oversight, allowing us to focus on creativity, innovation, and connection. With software, we can ensure systems operate efficiently, reducing human labor for mundane tasks.

Example: Automated systems in agriculture and energy management optimize production and distribution, ensuring everyone’s basic needs are met without human micromanagement.
Automation helps maintain balance and sustainability, focusing on optimal resource use rather than profit margins.

* 🌐 Democratization: Empowering and Uplifting Communities
RBE emphasizes equal access to technology and tools that empower individuals and communities. Software democratizes not just knowledge but also problem-solving, spreading opportunities for growth and innovation.

Example: Tools for critical thinking and collaborative decision-making enhance personal and collective problem-solving, rippling through entire communities.
By sharing knowledge and tools, we amplify collective intelligence, spreading abundance far beyond individual users.

* 📊 Optimization: Aligning Needs with Resources
Software-driven optimization ensures that population needs are met with the resources we have, minimizing waste and ensuring equity. In RBE, this alignment is key to sustainability and abundance.

Example: Real-time data systems optimize resource allocation, such as water or food distribution, ensuring no resource goes to waste while meeting everyone’s needs.
Optimization shifts focus from maximizing profit to maximizing well-being, fostering a balanced, thriving society.

* 🤝 Collaboration: The Foundation of Thriving Systems
In nature, success comes from collaboration, not competition. RBE mirrors this by prioritizing collective well-being over individual gain. Software enables systems where collaboration is the main goal, fostering shared progress across politics, finance, and society.

Example: Platforms for collective resource management, such as community energy grids or cooperative business models, align individual efforts with communal goals.
When collaboration becomes our core value, we build systems that are resilient, adaptable, and abundant.

* 🚀 Scalability: Amplifying Global Impact
Information and solutions are infinitely scalable, enabling a global shift toward abundance. RBE leverages this scalability to ensure that knowledge and resources flow seamlessly across borders and systems.

Example: A localized healthcare software solution can scale globally, improving healthcare systems worldwide while adapting to local contexts.
Scalability ensures that abundance isn’t confined to one region or group—it becomes a global standard.

** The Vision: From Scarcity to Abundance
Jacque Fresco’s vision of a Resource-Based Economy reimagines how we manage our world’s resources. It shifts the focus from profit to purpose, from individual gain to collective well-being. Software is a critical enabler of this transition, allowing us to:

* Automate the unnecessary,
* Democratize tools and knowledge,
* Optimize resource allocation,
* Foster global collaboration, and
* Scale impact to benefit all of humanity.

The path to abundance isn’t through hoarding or competition—it’s through sharing, balancing, and thriving together. Let’s build a future where software helps us live in harmony with our planet and each other. 🌍✨

<style class="fallback">body{visibility:hidden}</style><script>markdeepOptions={tocStyle:'long'};</script>
<!-- Markdeep: --><script src="https://casual-effects.com/markdeep/latest/markdeep.min.js?" charset="utf-8"></script>
 <meta charset="utf-8" emacsmode="-*- markdown -*-">
# How did I generate a QR so our clients could write a review 
September 30th, 2024
by *Pepe Hernandez*

###Portfolio ###Hacks ###ProgrammingAdventures

My wife asked me for a QR code so their clients could write a review in Google Maps. As you know, when a woman asks a man to do something, the man will do it; you don't have to remember the task every six months. As I know myself, I started as soon as possible, just before a kind reminder came to me.

## 1st iteration. Found the URL on Google Maps. Find a tool to generate the QR. Generate it.
The first thing I did was go to Google Maps and find the URL of the business. I had the input to generate the QR. Then, I asked chatGPT, "How can I create a QR?"
It gave me three options: download Code Monkey or use a QR code generator. I tried both. I downloaded the QR code generator, but there is no app for Code Monkey on my iPhone. The third option was to generate the code using some Python libraries. I had to generate only one, so I chose to go with the apps. 
I had to pay for the 14th-day package of the QR code generator. 
It was okay, but you have to scroll until the review section, which creates a little friction for the customer. I was not happy with it. 

## 2nd Iteration. How do you get a direct URL to publish the review?
I asked CHATGPT how to do this. It gave me two options: First, add the URL /review, which didn't work. 
The second option is generating the URL using the PLACE_ID with the next link:
https://search.google.com/local/writereview?placeid=PLACE_ID

Now I asked, "How do I get the PLACE_ID?" The direct place ID is a HEXADECIMAL number that you can extract from the sharing URL of the place. However, this doesn't work. 

It generates an error:
404. That's an error. The requested URL /local/writereview?placeid=0x8f56777791707875:0xf7ed452d4b2d8269 was not found on this server. That's all we know.

I asked CHATgpt about it. The reason is that the HEXADECIMAL format is incompatible with the suggested link to go directly to the review.
To get the right PLACE_ID, CHATgpt suggested going to the Google Developers site: https://developers.google.com/maps/documentation/places/web-service/place-id and looking for the PLACE.
I got the right PLACE_ID.
Here you can write your review:
https://search.google.com/local/writereview?placeid=ChIJM9B-Nap1Vo8R-decYH9-KV4

## Finally, I tuned the QR using the QR Generator
I used a template.
I selected a logo.
I shared the QR with my wife.

![Add your review! Quiriquiqui](QRQuiquiriqui.jpg)

And those who are married know, "Happy wife, happy life."

<style class="fallback">body{visibility:hidden}</style><script>markdeepOptions={tocStyle:'long'};</script>
<!-- Markdeep: --><script src="https://casual-effects.com/markdeep/latest/markdeep.min.js?" charset="utf-8"></script>

<meta charset="utf-8" emacsmode="-*- markdown -*-">

# Declarative dotfiles with Home Manager

October 5th, 2024
by *Julio César*

## What are dotfiles?

The UNIX philosophy is a set of cultural norms and a philosophical approach to building minimalist and modular software, the main tenets can be summarized as follows:

-   Write programs that do one thing and do it well.
-   Write programs to work together.
-   Write programs to handle text streams, because that is a universal interface.

While I am a big supporter of the idea, is not without drawbacks. As a software developer in a Linux system I often end up installing lots of small utilities each one needing its own configuration file. It&rsquo;s not uncommon to have lots of these configuration files lying around polluting the home directory. In an attempt to keep these out of the way their names usually start with a dot (`.`) meaning they are &ldquo;hidden&rdquo; and not listed by programs such as `ls` or any other file browser for that matter (at least by default), however, they&rsquo;re still there accruing into a bigger configuration file collection over time, these are commonly known as &ldquo;*dotfiles*&rdquo;.

In order to ease management of these configuration files it is often practical to start viewing them as code, after all they define the state of the system we use to do our work, because of this reason it is not uncommon to check these files into version control systems so that we&rsquo;re able to share the same configuration across multiple machines with the added benefit that if we ever need to change workstations then it would be easier to port our tools over and get to work right away (which in my experience - it&rsquo;s never that easy).

However, managing these files in a software repository brings on a new challenge as we now need to handle the installation of these files into their correct locations, not all dotfiles need to be in the home directory and not every tool supports the [XDG Base Directory Specification](https://specifications.freedesktop.org/basedir-spec/latest/) so it&rsquo;s not uncommon to have non-standard locations for these files, more over tools which provide lots of functionality might end up needing more than one configuration file for them to work.


## The symlink approach

Take the following dotfiles repository as an example:

```
$ tree --charset=ascii ~/configuration/dotfiles
.
|-- .ghcid
|-- .git/
|-- bat/
|   `-- config
|-- doom/
|   |-- config.el
|   |-- init.el
|   `-- packages.el
|-- fourmolu/
|   `-- fourmolu.yaml
|-- nix/
|   |-- netrc
|   |-- nix.conf
|   `-- registry.json
|-- nvim/
|   `-- init.vim
`-- setup.sh
```

One option would be to use symbolic links to install this configuration into place:

```
$ ln -s ~/config/dotfiles/bat ~/.config/bat
$ ln -s ~/config/dotfiles/doom ~/.config/doom
$ ln -s ~/config/dotfiles/nix ~/.config/nix
...
```

Unfortunately we can&rsquo;t symlink the whole repo into `~/.config` because this directory might not be empty and contain other files that we don&rsquo;t want to track in our dotfiles repository, so the next intuitive thing to do might be to iterate through each of the directories and symlink each file into place, here is a one liner to do exactly this:

```
$ find . -type d -exec ln -s {} ~/.config/ \;
```

Ok but what about the `.git` folder that exists in all git repositories, or suppose I have a `docs` folder in my repo that doesn&rsquo;t hold any configuration files at all? I don&rsquo;t want these directories to be symlinked!

With this symlink approach it isn&rsquo;t hard to find ourselves in a situation where we start to loose flexibility, for instance, all of a sudden a tool&rsquo;s configuration might need to be placed in a different location due to an upstream change. Next, we find ourselves coding a script with all these rules in it, yes, that&rsquo;s precisely why there&rsquo;s a `setup.sh` script in the dotfiles folder above. I&rsquo;ll give you a sneak peak into what that file might look like; young children close your eyes:

```bash
#!/usr/bin/env bash

set -xeumo pipefail

self="$(realpath "$0")"
this="$(dirname "$self")"

# Create symlinks so config appears in right folder
# ln -sT "$this/.lesskey" "$HOME/.lesskey"
# ln -sT "$this/dunst" "$HOME/.config/dunst"
ln -sT "$this/.ghci" "$HOME/.ghci" || echo "WARN: .ghci config already exists"
ln -sT "$this/fourmolu" "$HOME/.config/fourmolu" || echo "WARN: fourmolu config already exists"
ln -sT "$this/.clang-format" "$HOME/.clang-format" || echo "WARN: .clang-format config already exists"
ln -sT "$this/nvim" "$HOME/.config/nvim" || echo "WARN: nvim config already exists"
# ln -sT "$this/bat" "$HOME/.config/bat"
# ln -sT "$this/containers" "$HOME/.config/containers"

# This should execute only when xmonad support is desired
# # TODO Should link as well
# mkdir -p $HOME/.local/share/sounds/
# cp $this/share/sounds/* $HOME/.local/share/sounds/
# cp $this/share/icons/* $HOME/.local/share/icons/

# TODO Setup the following snap packages as well (in a function)
function setup_snaps () {
    snap install dbeaver-ce firefox gnome-clocks slack snapd-desktop-integration element-desktop
}

# TODO Link nix and nixpkgs configuration into place
# ln -sT "$this/nix" "$HOME/.config/nix" || echo "WARN: nix config already exists"
# ln -sT "$this/home-manager" "$HOME/.config/home-manager" || echo "WARN: home-manager config already exists"
ln -sT "$this/doom" "$HOME/.config/doom" || echo "WARN: doom config already exists"

# link share resources
# TODO Add a check to make sure the "icons" and "applications" directories exist, and if not create them
ln -sT "$this/share/fonts" "$HOME/.local/share/fonts" || echo "WARN: ~/.local/share/fonts already exists"
ln -sT "$this/share/icons" "$HOME/.local/share/icons" || echo "WARN: ~/.local/share/icons already exists"
# TODO probably need to fix globbing
ln -s $this/share/applications/*.desktop "$HOME/.local/share/applications/" || echo "WARN: conflicting links/files in ~/.local/share/applications"
```

I don&rsquo;t know about you, but that looks nasty! it certainly does read &ldquo;fragile&rdquo; all over the place to me, you can even see we do not check if the files where already installed and might be overwritten, or whether the target directories exist at all. We might get into arguments on what approach the script should take and how it should be structured in order to improve the situation, but my point stands, scripting a configuration into place will never be good enough and as such is not the right approach to configure an environment.


## Home Manager for declarative configurations

As a neophyte Nix user I had to try Home Manager for solving exactly this problem, and what a great solution this is!

Home manager allow us to follow the philosophy of NixOS to manage our dotfiles, that is, whereas NixOS allow us to configure an entire system state and system-level properties declaratively using the Nix language, Home Manager allow us to configure our user-level tooling declaratively using the Nix language.

Nix being nix, exposes lots of possible ways to do the same thing, so I will document bellow the way I&rsquo;m currently using it in combination of Nix Flakes, a fancy name for &ldquo;*a unit of Nix distribution package*&rdquo;.

Within the root of the dotfiles repo we define a `flake.nix` file, this is a file that implements a known schema of what a *flake* should look like, in essence it must define an object with certain properties set, or in Nix lingo, an attribute set with certain definitions in it, it&rsquo;s all the same, the code is properly commented to explain each part:

```nix
# flake.nix
{
    # Adds a sample description as metadata for this flake
    description = "This Flake manages my dotfiles";

    # The "inputs" attribute is used to declare what other flakes
    # this flake depends on - it is essentially our dependency list
    inputs = {

        # We can depend on other flakes that are hosted at github by their URL.
        #
        # Nixpkgs is a big set of packages that is almost always depended upon
        # as it contains Nix's standard library.
        #
        # It is possible to pin dependencies to a specific commit (aka revision)
        # for example in this case we pin to a commit on the nixos-24.05 branch
        # of the "NixOS/nixpkgs" reposityory. We can obtain these either by
        # looking in github directly or by browsing https://status.nixos.org/.
        nixpkgs.url =
          "github:NixOS/nixpkgs?rev=36bae45077667aff5720e5b3f1a5458f51cf0776";

        # The nixos-XX.YY branches contain stable packages known to work reliably,
        # however, this means that software packaged in that branch might not be
        # the latest available, for that we can declare another version of nixpkgs
        # this time pinning a revision from the "nixpkgs-unstable" branch which
        # typically has the "latest" available versions of most packages:
        unstable.url =
          "github:NixOS/nixpkgs?rev=5de1564aed415bf9d0f281461babc2d101dd49ff";

        # Home Manager is distributed as a flake itself, so we add it
        # here as a dependency to our flake, the revision comes from
        # the "release-24.05" branch
        home-manager.url =
          "github:nix-community/home-manager?rev=e1391fb22e18a36f57e6999c7a9f966dc80ac073";

        # Since Home Manager is a flake itself written in Nix then it surely
        # declares nixpkgs as one of its dependencies, since our flake already
        # depends on nixpkgs it would be nice to tell nix to use the exact same
        # Nixpkgs version that our flake depends on when Home Manager's nixpkgs
        # dependcy gets resolved; we use literaly type "nixpkgs" here because
        # that how we named it in our inputs above.
        home-manager.inputs.nixpkgs.follows = "nixpkgs";
    };

    # The "outputs" attribute is a function that takes the "inputs" as
    # parameter (here we unpack it using object destructuring) and returns
    # an attribute set (aka an object or dictionary) that defines certain
    # attributes that follow the flake schema.
    outputs = { nixpkgs, unstable, home-manager, ... }:

      let
        # nixpkgs packages software for different architectures in my
        # case I only care about x86_64-linux so I refer to that on
        # its own as "pkgs".
        pkgs = nixpkgs.legacyPackages.x86_64-linux;

      in {

        # In this particular case "homeConfigurations" is not part of the
        # official flake schema but is an attribute understood by the
        # home-manager CLI tool.
        #
        # Here we declare a home manager configuration named "demo".
        homeConfigurations.demo =

            # home-manager configurations are instantiated by calling the
            # "homeManagerConfiguration" function, giving it an attribute
            # set as its only argument:
            home-manager.lib.homeManagerConfiguration {

              # The attribute set we give to the function expects a "pkgs"
              # attribute to be defined, it must be a nixpkgs package set,
              # in this case we use `inherit` as a shortcut for `pkgs = pkgs`.
              inherit pkgs;

              # Home manager - as well as NixOS - allow us to package our
              # configuration in modules, at the beginning we might only
              # have a single module but this can change later, perhaps
              # having a module per application configuration.
              modules = [
                # We refer to the file containing our home configuration as a module
                ./home.nix
              ];

              # Optionally we can set "extraSpecialArgs" to pass arguments
              # to home.nix and whatever other modules we might have
              # included in the "modules" list above.
              extraSpecialArgs = {

                # As an example we pass the "unstable" version of nixpkgs
                # so that we're able to use it within the home.nix module.
                inherit upkgs;
              };
            };
    }
}
```

Now, we need to define the `home.nix` file that we included by path in the `flake.nix` file:

```nix
# home.nix

# A module is no different than a function that takes an attribute set as its
# only parameter, here we deconstruct the object to access `pkgs` and `upkgs`
# that we passed in `extraSpecialArgs` earlier.
{ pkgs, upkgs, ... }:

{
  # We might include other modules if we have organized our configuration
  # in multiple files, you see, our configuration composes just like
  # Matryoshka dolls
  imports = [
    ./other-module.nix
  ];

  home.username = "demo";

  # Install syncthing and enable a systemd service that keeps it running
  services.syncthing.enable = true;

  # We can define environment variables we might need
  home.sessionVariables = {
    EDITOR = "nvim";
    COLORTERM = "truecolor";
    TERM = "xterm-256color";
  };

  # We can install Emacs and with some extra packages for Emacs to use
  programs.emacs = {
    enable = true;
    extraPackages = epkgs: with epkgs; [ vterm ];

    # We can tell it to use "emacs" but the one coming from
    # the unstable nixpkgs version "upkgs"
    package = upkgs.emacs;
  };

  # It is possible to say "put *this* file into *this* location".
  #
  # In this example we use it to "copy" a "ghci" configuration
  # file into our home directory as ".ghci".
  home.file.ghci = {
    enable = true; # If this is `false` then the file is not copied
    source = ./.ghci;
    target = ".ghci";
  };

  # A partial example on how we can install and configure git:
  programs.git = {
    enable = true;

    # These are attributes that git expects
    # in its `~/.config/git/config` file
    userName = "demo";
    userEmail = "user@demo.com";

    # We can alias commands, e.g. "git graph":
    aliases = {
      graph = "log --all --graph --decorate --oneline";
    };
  };

  # This value determines the Home Manager release that our
  # configuration is compatible with. This helps avoid breakage
  # when a new Home Manager release introduces backwards
  # incompatible changes.
  #
  # It is possible to update Home Manager without changing this value.
  #
  # Whenever we use flakes (as we are doing) this value isn't really used
  # because we specifically set the home-manager revision to use as a flake
  # input, however, still must be present in the home configuration so that
  # it does not throw an error about "missing attribute".
  home.stateVersion = "23.11";
}
```

This is a bare example that shows how could we use Home Manager to configure our user-level tools, we can see how not only we&rsquo;re able to install packages such as Emacs or Git, but also add configuration to them. We can also manage arbitrary files (`home.file`) and set environment variables (`home.sessionVariables`).

Note that environment variables are only able to get injected if Home manager also configures our shell, this mentioned in the manual: [Why are the session variables not set?](https://nix-community.github.io/home-manager/index.xhtml#_why_are_the_session_variables_not_set), in the example above we did not configure our shell so if we wanted to see those variables we need to source a script home-manager installs, but, adding our shell configuration to home-manager is trivial.

```nix
# other-module.nix
{ ... }:

{
  # ...

  # Install and configure Zshell
  programs.zsh = {
    enable = true;
    autosuggestion.enable = true;
    enableCompletion = true;
    autocd = true;
    defaultKeymap = "emacs";
    dotDir = ".config/zsh"; # Where to place zsh config?

    # Define some shell aliases
    shellAliases = {
      cat = "bat -p";
      cd = "z";
      gs = "git status";
      l = "ls -alh";
      ll = "ls -l";
      ls = "ls --color=tty";
      lt = "ls -thalr";
    };

    # Use the popular Oh-My-Zsh distribution
    oh-my-zsh = {
      enable = true;
      plugins = [ "git" "direnv" "fzf" ];
      theme = "robbyrussell";
    };
  };

  # ...
}
```

After seeing all this, a natural question arises, how do I know what options are available to set in my Home Manager configuration? good news, all the options home manage supports are listed in the official manual [Appendix A. Home Manager Configuration Options](https://nix-community.github.io/home-manager/options.xhtml). I would also suggest [Home Manager Option Search](https://home-manager-options.extranix.com/) an option index for quick searching.


## Applying the Home Manager configuration

It&rsquo;s all fun and games till we want to apply our configuration, the very first time we do this we actually want to install Home Manager into our workstation, the following works given that we have Nix installed with Flakes support enabled:

```
$ nix run home-manager/release-24.05 -- init --switch
```

A temporary shell with `home-manager` available will be activated after running that command, and will bootstrap our configuration in the process.

From this point onwards whenever we modify our configuration `home-manager` can be executed directly to switch to the new configuration:

```
$ home-manager switch --flake .#demo
```

We use `demo` here because that&rsquo;s the name we gave to our Home Manager configuration within the `flake.nix` file.


## Conclusion

I know what you might be thinking, &ldquo;*this doesn&rsquo;t look any simpler!*&rdquo;, &ldquo;*uh&#x2026; ever heard of GNU Stow?*&rdquo;, &ldquo;*Nix is hard*&rdquo;, &ldquo;*I use Windows*&rdquo;, &ldquo;*what is this post even about?*&rdquo;. Shh! when we start to treat our configuration files as any other software codebase, then using a declarative functional language to manage it is a smart move.


<style class="fallback">body{visibility:hidden}</style><script>markdeepOptions={tocStyle:'long'};</script>
<!-- Markdeep: --><script src="https://casual-effects.com/markdeep/latest/markdeep.min.js?" charset="utf-8"></script>
<meta charset="utf-8" emacsmode="-*- markdown -*-">

# Devtron: Enhancing Kubernetes Management and DevOps Pipelines

October 16th, 2024
by *Leonel Perea*

## Introduction

As organizations continue adopting Kubernetes for containerized applications, they encounter several operational and developmental challenges. Kubernetes, while highly scalable and flexible, demands a deep understanding of cluster orchestration, debugging, and CI/CD pipelines, which often overwhelms DevOps teams. Devtron https://devtron.ai/ presents itself as a unified platform to simplify these tasks. This research paper delves into how Devtron integrates with Kubernetes, providing solutions to container orchestration, security management, and application deployment.

## Problem Statement

Organizations utilizing Kubernetes face challenges in:
- **Complex application management**: Orchestrating multi-cluster environments.
- **Debugging and observability**: Identifying root causes in distributed environments.
- **Security vulnerabilities**: Ensuring continuous security scanning of applications.

Devtron seeks to address these challenges by providing a Kubernetes-native platform that integrates with existing DevOps workflows.

## Simplified Application Management

Devtron offers a centralized dashboard that provides complete visibility over Kubernetes clusters, pods, and applications. It allows users to monitor cluster resources, check logs, and manage deployments through a single interface. This eliminates the need for complex command-line interactions, simplifying Kubernetes adoption.

- **Resource Grouping**: Devtron groups resources, such as networking, storage, and compute, into intuitive categories. This helps users debug issues faster, as all related components are neatly organized in the UI.
- **Multi-Cluster Management**: The platform allows users to manage multiple Kubernetes clusters from one central location, making it suitable for enterprises with complex multi-cloud or hybrid cloud environments.

## Enhanced CI/CD Pipelines

One of Devtron's strongest features is its integration of CI/CD pipelines into Kubernetes. Devtron automates the build, test, and deployment phases for applications, leveraging Kubernetes as the base infrastructure for these processes.

- **Continuous Integration (CI)**: Devtron integrates with common CI tools and allows easy deployment of application changes. It provides Dockerfile templates for easy containerization, enabling teams to standardize the CI process.
- **Continuous Deployment (CD)**: Devtron integrates with Helm, allowing easy deployment of Kubernetes resources. Its Helm dashboard provides visibility into Helm charts, enabling users to manage and monitor applications deployed across clusters more efficiently.

## Debugging and Monitoring

Debugging distributed systems like Kubernetes can be complex. Devtron simplifies this by providing access to logs, pod-level events, and a built-in terminal, allowing teams to debug applications directly from the dashboard. This real-time debugging capability helps reduce downtime and speeds up resolution times.

- **Log Monitoring**: Devtron allows users to view application and Kubernetes logs in real time. It supports automated log collection and organization by application, pod, or namespace.
- **Interactive Shell**: Users can access an interactive shell for each Kubernetes pod, allowing them to run commands and inspect the state of the application from within the pod itself.
- **Event Tracking**: The platform logs key events, helping teams trace the root cause of issues, such as failed deployments or pod crashes.

## DevSecOps Integration

Security is a critical concern in cloud-native environments. Devtron addresses this by integrating security scanning into the deployment pipeline and enforcing access control policies.

- **Security Scanning**: Devtron integrates with tools like Trivy to perform vulnerability scans of containers and Kubernetes resources before deploying them to production. This ensures that no vulnerable code is deployed to production environments, maintaining a secure pipeline.
- **Fine-Grained Access Control**: The platform provides detailed access control, allowing teams to assign specific permissions to users or groups. Devtron supports Role-Based Access Control (RBAC), which is abstracted to a user-friendly UI, making it easier for DevOps teams to manage access across multiple projects and environments.

## Policy-Driven Security

Through Devtron, teams can enforce security policies on Kubernetes resources to ensure compliance with organizational standards. These policies can cover a range of topics from image scanning to infrastructure monitoring, ensuring that only secure and compliant applications are deployed to production.

## Multi-Environment and Multi-Cloud Support

Devtron's support for multi-environment and multi-cloud configurations makes it a valuable tool for enterprises that operate in hybrid environments. It allows organizations to manage configurations specific to development, testing, and production environments, ensuring consistency across different clusters.

- **Parallel Deployments**: Devtron facilitates simultaneous deployments to multiple environments, reducing the complexity of managing different configurations for staging, production, and development clusters.
- **Environment-Specific Configurations**: Each environment can have unique configurations managed directly within the Devtron platform, allowing for efficient management of application settings across diverse environments.

## Operational Efficiency and Cost Management

Devtron introduces features that help reduce the operational overhead of running Kubernetes. Its dashboard provides real-time insights into resource usage, helping teams optimize their deployments and scale their infrastructure according to demand.

- **Hibernation of Workloads**: Devtron enables organizations to scale down non-critical workloads during off-hours, reducing operational costs. This feature is particularly useful for managing non-production environments such as staging and testing.
- **Real-Time Monitoring**: The platform provides live monitoring of deployments and Kubernetes resources, allowing teams to make informed decisions about scaling or resource allocation.

## Conclusion

Devtron serves as a comprehensive platform for managing Kubernetes clusters, CI/CD pipelines, and security workflows. Its integration with Helm and Kubernetes makes it an ideal choice for organizations seeking to streamline application deployment, monitor performance, and enforce security policies. By reducing the complexity of managing Kubernetes and providing a single platform for CI/CD, DevSecOps, and cloud-native applications, Devtron helps organizations maximize the benefits of Kubernetes while minimizing operational overhead.

<style class="fallback">body{visibility:hidden}</style><script>markdeepOptions={tocStyle:'long'};</script>
<!-- Markdeep: --><script src="https://casual-effects.com/markdeep/latest/markdeep.min.js?" charset="utf-8"></script><meta charset="utf-8" emacsmode="-*- markdown -*-">

# Did you read this book? Great, show me...
By Pepe Hernández, November 3rd, 2024

# I like to read.

I like to read.
I wish I could have more time to read.
As I don't have too much time to read, I need to take some shortcuts.
First, I use audible. 
I enjoy running for 30 minutes daily while listening to the chosen audiobook. Last month, I listened to and re-listened to Cal's Newport Slow Productivity book. I also re-listen to one of my favorites, Steven's Pressfield, "Put your ass where your heart wants to be." I will buy both books physically. They are worth it.

## A pair of learnings from each book

### Cal's Newport Slow Productivity

**I discovered some stories that show that slow productivity works**. Cals Newport writes about how vital work is and how it took years, even decades, to finish. Newton, Galileo, Jane Austin, Einstein, and other great achievers had problems in their minds and worked on them for many years. They were persistent, patient, and slow productivity workers. They worked a pair of hours and then followed with the daily activities. But they continually came back to their stuff, to their problem.
**I found another interesting Kanban case in the book**. 
Another exciting learning is that the Genoma Research Center of Boston's business case used Kanban to achieve an excellent operating performance. A sustainable pace is one of Kanban's values. The lab's IT and software departments adopted Kanban to improve software delivery. 

### Steven Pressfield, "Put your ass where your heart wants to be"
You can use many quotes to be on your thing when you are working. Also, the book contains recommendations to motivate you to outperform in your field. This is mainly for artists and writers, but you can generalize this to every human field.

- This is the day; there is no other day.
- This is the wor, there is no other work.
- Move your ass all the way, related to marketing.
- Kill-kill = good, good
- Among other advice.

Both books are highly recommended.

## Reading the Physical book, "Scaling Up".
For other motifs, I am reading Vern Harmish's book Scaling Up. I am working right now, helping my family use this framework in their company.

When I read a book, I try to understand the message. Frequently, I elaborate on something. I've made a presentation, prepared material, written a post, or done something else. 

So when I recommend a book, I have a general understanding of it. I could talk about it. This is obvious, at least for me. But is it for everybody else?

## Did you read X book?

So frequently, when I talk to somebody about a specific topic, I remember a book, a phrase, a quote. And I ask, that comes from this particular book. Did you read it? Sometimes, people ask me, "Yes, of course." The younger me smiled, agreed, and continued with the talk to realize that people hadn't read the book for the following talk, or, if they had read the book, they hadn't understood the content, or the message, or thought bad, they only told me they read the book, but it wasn't true. 

When this happens to me, now I ask, "Great, what do you think about the book?" What did you learn? Did you like it, and why? I do that not because I want to put them in evidence of lying to me or us. I do that because when I say something, I frequently don't finish my idea because I think other people already understand or know what I am trying to say. 

I adopted this habit because Alex uses it frequently. We have a WhatsApp group of friends. The group aims to recommend movies or tracks. Its original name is cine cata (cine, for cinema, and data for the analogy of wine-tasting events for enthusiasts and specialists). When somebody adds a recommendation, Alex always asks, "Why did you like it?" That means you should give me more information to check my interest.

As an expert in something, there is some knowledge you think is obvious. For example, bottlenecks determine the performance of the system. It's obvious, isn't it? Yes, but the second level of understanding is not. You realize that when people know the bottleneck, they continue improving the 99% of elements that are not the bottleneck. When you ask, what will you improve? That lets you know that they don't understand bottlenecks. 
Experts understand deeply simple things in their domain.  

If you know something as an expert and someone tells you they understand the concept, you believe them because it is obvious. This is a trap.

Did you read this book? Did you know this concept? - you will ask.
Yes, of course - people will answer.
Then you believe. You have fallen. You lose an opportunity.

	"What is obvious, is obvious (only) to You" - John Medina.

John Medina, author of Brain Rules and Brain Rules for Kids (both excellent books), said, "What is obvious is obvious to you." Because what you are trying to say is not apparent to anybody else. You need to say it to be understood. Yes, I know. It's not only me. Everybody makes connections with his experience or with the knowledge he has acquired throughout his life. 

## Teaching from the Back of the Room

There is another story that I like to share. I have some friends who have been teachers for a long time. A month ago, a friend of mine shared with me that their students of a class ignored them, and some of them told them, you repeat the concepts many times. Your class is boring because you repeat it continuously. She was reflective. I recommended that she ask their students what they have learned. To ask more, to listen more, and to talk less. "Can you explain to me the concept, idea, technique, and tool I have already shared with you?" When students answered, she knew if students had understood the concept. And she could give them good feedback in advance. Her classes have improved with the use of this principle. 

I discovered this principle in a Kanban University training course. Asking participants about Kanban methods' core practices lets facilitators know if they understand the concept or if they identify the gaps to give the participants good feedback. 

A final thought.

## People frequently think they know, but they don't. 

When this happens, go deeper. Both parts win.

<style class="fallback">body{visibility:hidden}</style><script>markdeepOptions={tocStyle:'long'};</script>
<!-- Markdeep: --><script src="https://casual-effects.com/markdeep/latest/markdeep.min.js?" charset="utf-8"></script>
<meta charset="utf-8" emacsmode="-*- markdown -*-">

# Extending the Power of Your Personal Cloud with Development Tools

## Tools for a Development Personal Cloud
October 26th, 2024, by Agus Rumayor

When building a personal cloud, the goal is not just storage or compute but creating a robust, versatile environment. For developers, this setup can include everything from managing web assets to container orchestration and IoT device control. Here’s how these tools fit together in a development-focused cloud.

### 1.1 Min.io for Web Asset Management
Min.io is a powerful open-source object storage tool, compatible with the S3 API, that allows for seamless management of web assets. With Min.io in your cloud, you can:

Store and serve static assets like images, videos, and files for web apps.
Scale storage efficiently, making it ideal for projects with expanding data needs.
Integrate with web frameworks through its S3 compatibility, simplifying data handling in your applications.
By handling web assets locally, you gain more control over data security and reduce reliance on external storage solutions.

### 1.2 Portainer for Container Management
Portainer brings simplicity to container management. With Docker and Kubernetes capabilities, Portainer’s visual interface makes it easy to:

Deploy and monitor containers, supporting rapid testing and iteration.
Manage permissions and access with role-based access control, essential for collaborative projects.
Scale applications across environments, allowing you to deploy apps or services with ease.
Portainer is perfect for quickly launching new containerized projects and managing them in a personal cloud setting without the complexity of a command-line-only interface.

### 1.3 Coder for Development Environments
Coder creates consistent, cloud-based development environments, freeing developers from machine constraints. With Coder, you can:

Set up isolated workspaces that replicate production environments, enabling reliable testing.
Scale environments dynamically based on the complexity of the project.
Collaborate easily, letting team members access the same development environment remotely.
Using Coder, you can turn your personal cloud into a reliable development hub, accessible from anywhere while maintaining security and control.

### 1.4 ThingsBoard for IoT Device Management
If IoT is part of your projects, ThingsBoard provides a versatile platform for device management. With ThingsBoard, your personal cloud can:

Monitor device data using a customizable dashboard for real-time insights.
Manage workflows and rules to automate responses to device data.
Securely interact with connected devices through protocols like MQTT, HTTP, and CoAP.
ThingsBoard’s visualization tools and device management capabilities make it ideal for any IoT-based projects or experiments within your personal cloud.

## Additional Tools for Efficiency and Cost-Savings
### 2.1 Storj for Leveraging Extra Storage and Cost Efficiency
While not directly a development tool, Storj adds value to a personal cloud by letting you rent out unused storage. It’s a decentralized storage network that offers:

Monetization of spare storage to offset cloud costs.
Economical storage options for large files, encrypted and distributed across multiple nodes.
Additional data redundancy, making it a secure backup option.
For those seeking to maximize efficiency, Storj provides a way to share resources and reduce the fixed costs associated with a personal cloud.

## Architecture in Action
Let’s look at a scenario where these tools come together:

Scenario: New Feature Development and Testing
Imagine you’re developing a new feature for an IoT application and need to test it across multiple services. The process might go like this:

Coder sets up a consistent environment, mirroring your production setup. You develop and test code, deploying the feature to a local container using Portainer for quick access and control.
ThingsBoard manages IoT device telemetry, helping monitor device interactions in real time.
Min.io stores all necessary assets, such as configuration files, images, or firmware for IoT devices.
Storj is employed as a backup for critical data from Min.io, providing redundancy and sharing storage costs across the network.

## Why This Setup?

These tools are all integrated within the multi-layered proxy architecture, ensuring secure, controlled access to each service. For more details on how the proxy architecture is structured, check out this post: [Multi-layered Proxy Architecture for my Personal Cloud](https://jagcoop.github.io/posts/Multi-layered_Proxy_Architecture_for_my_Personal_Cloud/).

Security: By integrating only private and secure services, this setup gives full control over your data and applications. Scalability: Kubernetes and Docker provide flexibility to scale services, while Portainer and Coder simplify management. Cost-Effective: Tools like Storj help monetize spare storage, lowering overall costs compared to relying solely on public cloud services.

This setup transforms a personal cloud into a comprehensive development environment, built with control, flexibility, and efficiency in mind.

<style class="fallback">body{visibility:hidden}</style><script>markdeepOptions={tocStyle:'long'};</script>
<!-- Markdeep: --><script src="https://casual-effects.com/markdeep/latest/markdeep.min.js?" charset="utf-8"></script>
<meta charset="utf-8" emacsmode="-*- markdown -*-">

# A Kanban Case Study in the Public Sector (Part I of N)

Octuber 14th, 2024
By Pepe Hernandez

By the end of 2017, several Department of Education administrative units had unspent budgets, and the fiscal year was nearing its end. Given the success of the Self-Construction Program team, the Zacatecas Education Agency decided to allocate unspent resources from other programs to the self-construction program. Thanks to this budget, the team could double the number of requests attended, a significant achievement considering that the annual resources needed to be more to meet all the needs of public schools. In the following years, the same phenomenon happened. The self-construction program used remanent resources from other programs. The team was proud of their Service's impact on the Zacatecas's childhood. 

It hasn't always been this way.

The Self-construction program was tripartite. The Education Agency of the State, the Municipal Governments, and School Parent Associations signed a legal agreement to participate in the program. The Education Agency provided materials and coordination through the Department of Self-Construction. The school parents' association provided social supervision. The municipal government provided labor. Some municipal governments signed an agreement and supported all the requests from schools with labor. Some of the work only needed the Parents' work and the materials provided by the Education Agency. 

The team was small: the Service manager (and other services), the supervisor coordinator, three supervisors, and the documentation specialist. There was a lot of work in progress or WIP (the work started but still needed to be finished). They didn't have a way to visualize the WIP. All they knew was that they were busy all day. They had a commitment to their purpose, but they felt stuck. But the natural explanation of reality was that the acquisition area was blocking our work. As humans look for a rational explanation of reality. We don't believe that it's our fault. It's somebody else. In this case, the acquisitions area was responsible for delaying materials. However, this limiting belief prevented them from acting on what was within their control.

Stephen Covey, author of The Seven Habits of Highly Effective People, states that **"when we think the problem is outside, that thought is the problem."** The team of the Self-Construction Program believed that the Department of acquisitions needed to be improved. However, this limiting belief prevented them from acting on what was within their control.

The introduction of a physical Kanban board revealed the partial truth. Of the 84 tickets in the "Preparing for Acquisition" column, only 37% of the work was pending acquisitions. The remaining 63%, or 139 tickets, had already passed through this phase and were in stages of building, finishing, and closing. With this new visibility, the team prioritized finishing those 139 tickets, freeing up space for new projects after the acquisitions area could do its job (acquiring materials from vendors). 

The team focused on following the Work In Progress in the columns ahead of the Acquisition in Progress step. The team needed to be more stable and was able to focus their attention on facilitating communication with stakeholders. The supervisor knew which requests required supervision, and the coordination area could make calls to update the state of the work. The team could detect external blockers, like delayed work due to unprovided municipal labor. Requests started to finish more frequently. The WIP decreased, and it was time to ask for help in the acquisition area. 

The head of acquisitions committed to attending weekly meetings to review the cases "blocked" by the area. In the first meeting, it became clear that his Department was a bottleneck. The team had labeled tickets with green stickers after each month, tickets had been spent in the acquisition process, and some had been stuck for six months or more, especially in public bidding cases. With this level of transparency, the acquisition area was aware of their importance in the process. They took action, and several tickets began to move. The head of the Department recognized the impact that waiting times had on project delivery.

There are several things I learned with this Kanban initiative, like:
- Establishing gradually Kanban Core Practices
- Limiting the Work in Progress
- Finding the criteria for the work done Determining policies of the system
- Using metrics to manage a significant volume of work (Core Practice 3. Managing Flow)
- One Kanban Board to rule all the requests
- The Physical Kanban Board evolution
- From a physical Kanban Board System to a Digital Kanban System

...

I will talk about some of what I learned next week. 

<style class="fallback">body{visibility:hidden}</style><script>markdeepOptions={tocStyle:'long'};</script>
<!-- Markdeep: --><script src="https://casual-effects.com/markdeep/latest/markdeep.min.js?" charset="utf-8"></script>
<meta charset="utf-8" emacsmode="-*- markdown -*-">
# How I fell in love with Serious Games for teaching Kanban (PART I)
October 28th, 2024
by *Pepe Hernandez*

## My first contact with Serious games

	"First experience, then theory." - Mike Burrows.  

Mike Burrows, author of Kanban from the Inside and Agendashift, said, "First experience, then theory." This is a powerful pedagogical principle.

We played the Get Kanban Game when I attended my first workshop with David Anderson from Kanban University in 2015. It was very engaging, and I also understood the game's mechanics. You can discover bottlenecks and identify several key concepts of the Kanban Method—everything in less than four hours. 

The Get Kanban Game is a serious game simulation created by Rusell Healy in 2011. Russel is a well-known Kanban specialist. He designed the Get Kanban game in the early days of Kanban and was awarded as a great contributor to the knowledge of the Kanban community. He was recently recognized as a Distinguished Kanban Fellow of Kanban University. 

You can buy the game at https://getkanban.com/.
- There is a free version of the game that you can print and play whenever you want. 
- There is a free online game version where you can play individually. You can play several times and change your strategy for better economic results. http://www.kanbanboardgame.com/ 

Note. There is a very different form of playing the game. That is for advanced players. "Improving GetKanban Scoreboards for Deeper Learning from the Game | by Alexei Zheglov | Medium." 

Since that firs time with Get Kanban Game, I fell in love with the general concept of **serious games**. The Get Kanban Game is a simulation embedded in a serious game. Simulations reproduce real-life settings to help players better understand the world (Gilbert & Troitzshn, 2005). Meanwhile, serious games focus on teaching players information or practicing specific skills while retaining the fun of the game. 

I used several times Get Kanban game. Every game, you learned something new. When I was preparing the first certification training course as an Accredited Kanban Trainer, I kept looking for more ideas about introducing Kanban to people. The GetKanban game is excellent for software development teams, software product teams, product managers, project managers, and Scrum Masters. However, it is not intuitive for other professionals. I've worked with public servants for a long time, so I needed more straightforward ways to introduce Kanban. I found a book that I enjoyed very much "Practical Kanban", writen by Klaus Leopold. There, I found simulations about building paper boats. While reading, I was sure that was a more straightforward, shorter way to introduce Kanban to people. 

I currently use GetKanban Game for the Kanban Systems Desing, but when I want to introduce the topic to people from different industries I use the Paper Boat Flow Simulation.


## The Learning Pyramid. A wrong and valuable model.
The Learning Pyramid said that the worst way to learn a topic is through a traditional lecture. On the other extreme, the best way to learn is by teaching. The second better way is through simulations or hands-on activities. The model makes sense, and supports the confirmation bias for me. I can learn better with games. Therefore, I started to look serious games and simulations for all my classes and workshops.

Unfortunately, the learning pyramid has proven to be ineffective. It was first proposed in a 1954 book called Audio-Visual Methods in Teaching, which the National Training Laboratories Institute developed. Empirically, I knew simulations were engaging, but learning things was not very effective. The model was wrong, but it was useful. When I use games and simulations, students engage with the topics. Even then, they could barely remember the key concepts. Nevertheles, that interest motivates them to give the method, principles, values, and practices a chance, and to be open for change. So, serious game are motivating, and engaging, but not effective for learning.

	"All models are wrong. But some are useful". - George E. Box.

In the thesis "A guide development for teaching Lean Startup using serious games," Ceballos, in 2021, created an instrument to evaluate learning from fundamental concepts of Lean Startup. The identification and comprehension of key concepts were very positive. Before introducing this tool, the questionnaire was only applied at the end of a series of plays, and the results were poor. Why did the introduction of a questionnaire before the serious game improve the learning results of the exercise?

## The right way to introduce serious games is to use proven methods, predict results, use spaced repetition, and predict results.

In his book, Small Teaching, James Lang remarks on the necessity of using the muscle of memory. When someone, even yourself, asks to remember something, you have more probability of remembering it. For example, James Lang attended a Starbucks for six months to buy frozen green tea. The same barista received the order day to day. When Lang asked what he would want, the barist could remember. But, the next day, the barista knew he wanted a frozen green tea. She could remember James, only when he ask her for his beverage.

The same principle was used for Ceballos in 2021. He made an initial questionnaire; it didn't matter what the participants answered. Some of them knew the topic, but not very well. But in the end, and during the process, they knew what answer they must look for during the game. This is a practical use of the prediction principle recommended by Lang in his book. Participants of a simulations, are aware of some specific questions, and while the evaluation happens students are answering the questions. As a side note, other valuable principles and practices are suggested in the Small Teaching book, like the interleaving principle (coming back to a specific knowledge) and spaced repetition practices, for example. This will be a topic for the following pòst. 

One of the things I like very much about Kanban training is the inclusion of good teaching practices, such as serious games, Case-Based Learning, and "Teaching from the Back of the Room," among others. This material would also be helpful for a future blog post.

Meanwhile we will be coming back to the Paper Boat Simulation workflow. How do you plan, how you execute, and how you close the simulation? We will answer the questions in the following blogpost.


-------

ps. I realized we have a lot of capital in serious games.
- We have played the GetKanban Game more than a thousand times
- The same for Featureban and Paper Boat Simulation
- We have several sources of collections of Lean-Kanban Games and Simulations.
-- Kirill Krimov. https://kirillklimov.com/kanban-games/
-- Full metal agilist. https://fullmetalagilist.wordpress.com/2020/04/08/simulaciones-kanban-a-distancia/
- We have three Master's Thesis about Serious Games (Kanban, Lean Startup, and Playing Lean).
- We have sold workshops for college teachers on using Serious Games.

Why is that? We are constantly looking for better ways to teach and learn.


<style class="fallback">body{visibility:hidden}</style><script>markdeepOptions={tocStyle:'long'};</script>
<!-- Markdeep: --><script src="https://casual-effects.com/markdeep/latest/markdeep.min.js?" charset="utf-8"></script> <meta charset="utf-8" emacsmode="-*- markdown -*-">
# Manage complexity behind simple interfaces

October 3rd, 2024
by *Julio César*

This is a follow up to the first post on [Understanding complexity in Software Systems](https://jagcoop.github.io/posts/Understanding_complexity_in_software_systems/) where we mentioned that a good software design is the one that reduces complexity of the system; complexity being anything that makes the system hard to understand and therefore modify.

In general, we can refer to the components of a system as &ldquo;*modules*&rdquo; and we can categorize them in mainly two groups, deep modules and shallow modules. The distinction comes mainly, from the size of the module interface and how well does it hide irrelevant details for most users of the module behind a properly designed interface. The reason on why this is of importance comes after the realization that complexity - while it can take many forms - the one area where it tends to creep-in is at the boundaries of modules, that is, at the interfaces. This is a key insight for software developers to grok - master the interfaces and keep complexity at bay.

To better understand what we mean by interfaces, recall that a software system is primarily an amalgamation of components, and for this to work every component in the system must expose some kind of interface, this is what tells users (and other modules) how are they supposed to use the &ldquo;thing&rdquo;, let it be a function, a method, a class, a package, a service, or a system on its own; all of these *objects* expose interfaces so that consumers know how to consume them.

Now, bringing it back to the categorization of modules, *deep modules* are the ones that hide a lot of complexity behind a simple interface so that users aren&rsquo;t bothered with understanding or even knowing about such complexities. A real-world example of a good deep module is the Linux I/O subsystem, there, users need only to know of about five system calls to do I/O interaction, mainly with files; programmers are often able to get away with just four of them, `open()`, `read()`, `write()` and `close()` (`lseek()` is the fifth one in case you were wondering). Behind these system calls there is a lot of complexity hidden that manages permissions, entries on a virtual file system, storage devices, memory mapping, and more, all of which is invisible to users.

In contrast to deep modules there are *shallow modules*, these are components of a system in which the interface leaks a lot of information about the implementation details of the thing, or worse, modules where the interface ends up being more verbose than the implementation of the module it self. Such small components shouldn&rsquo;t even exist, specially if used just in a couple of places through the codebase.

The information exposed by the interface of a module should be as small as posible without the need to make users understand the implementation of the module. This is the basis of the information hiding principle - an idea that has been preached before in other areas as well, &ldquo;the principle of the least information&rdquo;, &ldquo;don&rsquo;t make me think&rdquo;, etc.

In short, having simple interfaces is the secret sauce behind modular software, focus on defining small and simple interfaces and strive for deep modules that hide a lot of information users need not to care about; even better if we can still expose advanced functionality to power users through a different interface for those who need *more* out of the module, coming back to the  Linux I/O subsystem example - while rarely used - `lseek()` provides tighter control when reading files that some users might care about, specially the ones seeking to achieve higher performance or highly optimized programs.

In conclusion, by following these principles we will then make composition of modules on a system easier, just as we would like our jobs to be.


<style class="fallback">body{visibility:hidden}</style><script>markdeepOptions={tocStyle:'long'};</script>
<!-- Markdeep: --><script src="https://casual-effects.com/markdeep/latest/markdeep.min.js?" charset="utf-8"></script>
<meta charset="utf-8" emacsmode="-*- markdown -*-">

# Multi-layered proxy architecture for my personal cloud
October 8th, 2024
by *Agus Rumayor*

After writing the [Unlocking the power of personal cloud post](https://jagcoop.github.io/posts/Unlocking_the_Power_of_Personal_Cloud/), I felt compelled to dig deeper into the choice of technologies—examining not just which technologies we select, but why, when, and what older methods they are replacing.

First, let me clarify that today, the distinction between a **proxy** and a **gateway** has become increasingly blurred. In many instances, both terms are used interchangeably, and for good reason. As implementations grow more complex, proxies often incorporate robust security features, and gateways frequently employ proxy architectures to handle multiple protocols (HTTP, database, etc.). Therefore, moving forward, we will use the terms "Proxy/Gateway" to refer to technologies that utilize tunneling proxy architectures to secure access to services, regardless of which specific layer (application, network, etc.) is secured.

Traditionally, when we hear "tunneling proxy," our minds might immediately jump to the concept of a **VPN** (Virtual Private Network). VPNs have long been the go-to technology for securing connections between clients and servers, particularly for remote access. They create an encrypted "tunnel" through which data passes, protecting it from interception and unauthorized access. But modern tunneling proxy technologies have evolved to go beyond the scope of VPNs, incorporating more refined and efficient methods of securing communication, while offering additional flexibility for multi-protocol environments.

## The Shift from Traditional VPNs to Modern Proxy/Gateway Solutions
Historically, VPNs were used to secure connections at the network layer (OSI Layer 3), but this approach has its limitations. For one, VPNs operate on a more coarse-grained access control, meaning that once a user is authenticated and connected to the VPN, they can access a broad range of network resources, whether needed or not. This "all or nothing" approach presents a security risk, especially in environments where granular access control is essential.

Modern Proxy/Gateway solutions, on the other hand, offer a more fine-grained control. These systems allow organizations to secure access at the application layer (OSI Layer 7), meaning users are granted access only to the specific applications or services they need. This limits the attack surface and reduces the risks associated with over-permissive access.

Moreover, modern proxy/gateway architectures can also accommodate multi-protocol tunneling, meaning they can handle HTTP, database protocols (such as SQL), and even proprietary application protocols, all within a unified framework. This is a significant improvement over traditional VPNs, which are often limited to securing basic network communication protocols. There are a lot of major trends to search like Software-defined Perimeter (SDP), Zero Trust Network Access (ZTNA), API Gateway, Secure Access Service Edge (SASE) all these concepts combines and some implements each other.

## VPN architecture vs Multi-layered proxy architecture

VPN Architecture
**********************************************************************************************
*                                                                                            *
*                                                                                            *
*                                                                                            *
*                                                                                            *
*                                   xxxx xx x  x x  xxxx           xxxxxxxxx                 *
*                               xxxx                   xx   xx xxxx x  x  xxx                *
*                            xxx                        x xx                xxxxx xxx        *
*               xxxxxx    xxx                          xxx                           x       *
*          x xxx     xxxxxx                           xxx                             x      *
*        xx             x                             x                                x     *
*      xxx                                                                              x    *
*      x                                                                                x    *
*      x                                                                                x    *
*      x                                                                                x    *
*      x              ┌────────────────────┐                                            x    *
*      xx             │                    │                                            x    *
*        xx           │      VPN Client    │                                            x    *
*         xxx x       │                    │                                          xx     *
*               xx    └────────────────────┴──┐                                      xx      *
*                xx                           │   x                                xx        *
*                  xx                         │  xxxx                           xxx          *
*                   xx                        │xx    xx                       xx             *
*                     xxx                    x│       x xxxxx xxx xx x xx xxxx               *
*                       xxx              xxxx │            xxxxx      xxx                    *
*                          xxxxx xxx xxxx     │                 xxxxxxx                      *
*                                             │                                              *
*                                             │                                              *
*                                             │                                              *
*                                             │                                              *
*                                             │                                              *
*                                             │                                              *
*                                 ┌───────────▼─────────────┐                                *
*                                 │                         │                                *
*                                 │                         │                                *
*                                 │       VPN Server        │                                *
*                                 │                         │                                *
*                                 │           │             │                                *
*                                 └───────────┼─────────────┘                                *
*                                             │                                              *
*                                             │                                              *
*                                             │                                              *
*                                             │                                              *
*                          ┌──────────────────┼─────────────────────────┐                    *
*                          │                  ▼                         │                    *
*                          │            Personal Cloud                  │                    *
*                          │                                            │                    *
*                          │                                            │                    *
*                          └────────────────────────────────────────────┘                    *
*                                                                                            *
*                                                                                            *
**********************************************************************************************

Multi-layered proxy architecture
*********************************************************************************************************
*                                                                                                       *
*                                                                                                       *
*                                                                                                       *
*                                   xxxx xx x  x x  xxxx           xxxxxxxxx                            *
*                               xxxx                   xx   xx xxxx x  x  xxx                           *
*                            xxx                        x xx                xxxxx xxx                   *
*               xxxxxx    xxx                          xxx                           x                  *
*          x xxx     xxxxxx                           xxx                             x                 *
*        xx             x                             x                                x                *
*      xxx                                                                              x               *
*      x                                                                                x               *
*      x                                                                                x               *
*      x                                                                                x               *
*      x              ┌────────────────────┐                                            x               *
*      xx             │                    │                                            x               *
*        xx           │          Client    │                                            x               *
*         xxx x       │                    │                                          xx                *
*               xx    └────────────────────┴──┐                                      xx                 *
*                xx                           │   x                                xx                   *
*                  xx                         │  xxxx                           xxx                     *
*                   xx                        │xx    xx                       xx                        *
*                     xxx                    x│       x xxxxx xxx xx x xx xxxx                          *
*                       xxx              xxxx │            xxxxx      xxx                               *
*                          xxxxx xxx xxxx     │                 xxxxxxx                                 *
*                                             │                                                         *
*                                             │                                                         *
*                                             │                                                         *
*                                             │                                                         *
*                        ┌───┬────────────┬───▼──┬────────────────────┐                                 *
*                        │   │    Proxy 1 │      ┼─────────┐          │                                 *
*                        │   └────────────┼──────┘         │          │                                 *
*                        ├────────────────┼──┐             │          │                                 *
*                        │    Proxy 2     ▼  ┼──────────┐  │          │                                 *
*                        ├────────────┬──────┘          │  │          │                                 *
*                        ┼────────────┼───┐             │  │          │                                 *
*                        │  Proxy 3   ▼   ┼───────►     ▼  ▼          │                                 *
*                        ┼────────────────┘        Personal Cloud     │                                 *
*                        │                                            │                                 *
*                        │                                            │                                 *
*                        │                                            │                                 *
*                        └────────────────────────────────────────────┘                                 *
*                                                                                                       *
*                                                                                                       *
*                                                                                                       *
*                                                                                                       *
*                                                                                                       *
*                                                                                                       *
*********************************************************************************************************

To wrap up the discussion, it’s important to highlight the key differences between choosing a VPN architecture and a multi-layered proxy architecture for a personal cloud. Both options offer secure access to your data, but they serve different needs and come with distinct advantages depending on your use case.

1. Security Model
**VPN Architecture**: VPNs secure access at the network layer. When you connect to a VPN, your device becomes part of the private network, and all your traffic is routed through the VPN server. This secures your entire connection from end to end, regardless of what applications or services you use. However, once connected, you typically have access to everything on the network unless additional security measures are in place. This can increase the risk if any component inside the VPN is compromised.

**Multi-Layered Proxy Architecture**: A multi-layered proxy secures access at various protocol layers—typically at the application layer. Instead of securing the entire network, a proxy can be set up to only secure specific services or applications. For example, you can have a proxy that handles HTTP requests, one that manages database connections, and another that secures file sharing. This architecture is inherently more granular, offering fine-tuned security controls that limit access to specific resources and services, which minimizes the attack surface.

2. Granularity of Access Control
**VPN Architecture**: When using a VPN for a personal cloud, the access control is often broad—once authenticated, users generally have access to the entire network, regardless of the specific service or resource they need. This can create challenges for personal cloud deployments where you may want to limit access to only certain files, databases, or applications.

**Multi-Layered Proxy Architecture**: This offers fine-grained access control. Each layer or service can have its own access policies, allowing you to provide precise permissions for each user or device. For instance, you can allow access to a file-sharing service without exposing other resources like databases or web applications. This is crucial for minimizing security risks in personal cloud environments where different levels of access may be needed for different users or services.

3. Performance and Latency
**VPN Architecture**: VPNs encrypt and route all of your traffic through a remote server, which can introduce latency. This overhead may not be noticeable for small-scale personal clouds, but as the number of connected devices grows or the complexity of the data increases, VPNs can slow down performance.

**Multi-Layered Proxy Architecture**: Proxies can be optimized to handle specific types of traffic more efficiently, often leading to better performance. For example, a proxy handling only HTTP traffic can be tuned for that protocol, ensuring lower latency and faster response times for web-based services. In a multi-layered proxy setup, each proxy can be optimized for its role, reducing overall latency and improving performance for each individual service.

4. Complexity of Setup and Maintenance
**VPN Architecture**: VPNs are typically easier to set up and maintain for personal use. Many consumer-grade VPN solutions offer out-of-the-box configurations that require minimal technical expertise. The tradeoff is that you lose some granularity and flexibility.

**Multi-Layered Proxy Architecture**: Setting up a multi-layered proxy requires more technical expertise. Each proxy must be configured separately, and managing access controls at multiple layers introduces complexity. However, this also allows for tailored security and performance optimization, which can be beneficial for more advanced personal cloud setups that require specific controls over different services.

5. Privacy and Anonymity
**VPN Architecture**: VPNs are known for their ability to provide anonymity by masking your IP address and encrypting all of your traffic. For personal cloud users who want to ensure their connection is private and not traceable, VPNs are a strong choice.

**Multi-Layered Proxy Architecture**: While proxies also provide privacy by encrypting traffic and masking the user’s identity, they are generally more focused on securing specific services rather than providing broad anonymity. If privacy from third-party services or ISPs is a major concern, combining proxies with VPN-like functionality may be necessary.

### Final Thoughts: Which Architecture to Choose for a Personal Cloud?
Choose a VPN Architecture if your primary goal is simplicity, broad network access, and privacy for your entire connection. This is often ideal for users who want a basic, all-in-one solution to secure their personal cloud without diving into too much complexity.

Choose a Multi-Layered Proxy Architecture if you need fine-grained control, protocol-specific security, and scalability. This is the better option if you are running multiple services or applications in your personal cloud, and you want to manage access and performance on a more detailed level.

Both architectures have their place in securing personal cloud environments. The decision ultimately depends on the level of control, performance, and security you need for your specific use case. As personal cloud technology continues to evolve, integrating elements of both VPNs and proxy architectures might become the optimal solution, offering the best of both worlds.

<style class="fallback">body{visibility:hidden}</style><script>markdeepOptions={tocStyle:'long'};</script>
<!-- Markdeep: --><script src="https://casual-effects.com/markdeep/latest/markdeep.min.js?" charset="utf-8"></script>
<meta charset="utf-8" emacsmode="-*- markdown -*-">

# Turn GHC errors into links within Emacs' compilation buffer

October 18th, 2024
by *Julio César*

Emacs has a feature that allows to run compilation commands using `M-x compile`, it can run arbitrary commands but as the name implies compiling is its primary utility. Interestingly, whenever there&rsquo;s a compilation error the output indicates the file and line number where the error occurred, the cool thing about `compile` is that we can put the cursor over that line and press `RET` (that is, the return key) to jump into that location in an Emacs buffer.

The way this works is by defining a set of regular expressions that Emacs will use to identify *file location* patterns in the `*compilation*` buffer contents, these are set via the variables `compilation-error-regexp-alist-alist` and `compilation-error-regexp-alist`. The former is a keyed map (an associative list or *alist* in LISP lingo) of regular expressions with the error pattern to match for as the value, the key itself is not important but it should uniquely identify the regular expression associated to it. The second variable, `compilation-error-regexp-alist`, is a list of these keys that should be used to parse the `compilation-mode` buffer contents.

Emacs&rsquo; Haskell support it is what it is, and of course this feature doesn&rsquo;t work out of the box, but, to quickly jump to the offending line of an error message in my source code was a nice feature I wanted to have as part of my workflow.

There&rsquo;s `haskell-mode` which exposes a `haskell-compile` function that behaves pretty much identically to `compile` and that it has regular expressions loaded that makes the error output linking just work, sadly, it tends to become very slow on large buffers, like when there&rsquo;s a lot of compiler output or when there are lots of errors (which is often the case with GHC Haskell anyways).

However, the bright side is that `haskell-mode` already exposes regular expressions that we need in a list variable named `haskell-compilation-error-regexp-alist` so what&rsquo;s needed is to just copy these over to the sources used by the `compile` function, that is the `compilation-error-regexp-alist-alist` and `compilation-error-regexp-alist` variables we alluded to earlier.

Below there&rsquo;s a function that does this:

```elisp
(defun zz/load-haskell-compilation-error-regexp-alist ()
  "Integrate `compile' with Haskell Stack errors.

`haskell-mode' exposes `haskell-compile' as an alternative to `compile' with
regexes that allow linking errors to source files in the compilation buffer.
However, when using it, sometimes behave weirdly, here we copy those regexes to
the variables used by `compile' so that we are able to just use that and have
file links work."
  (let* ((idx 0)
         (regex-key (intern (format "haskell-error-%d" idx))))
    (dolist (regex haskell-compilation-error-regexp-alist)
      (unless (assoc regex-key compilation-error-regexp-alist-alist)
        (add-to-list 'compilation-error-regexp-alist-alist (cons regex-key regex)))
      (add-to-list 'compilation-error-regexp-alist regex-key)
      (setq idx (1+ idx)))))
```

Note that in order to use this, it is not enough to write it verbatim into our Emacs configuration, we must call it within a `(with-eval-after-load 'haskell-mode ...)` block, otherwise the `haskell-compilation-error-regexp-alist` variable won&rsquo;t be defined yet; Emacs Doom users can use the `after!` macro to achieve the same thing:

```emacs-lisp
(after! haskell
  (zz/load-haskell-compilation-error-regexp-alist))
```

Success!


## Enabling error pattern recognition in `vterm` buffers

To top it all off there&rsquo;s a minor mode in Emacs to get the same `*compilation*`-like behavior in the current buffer contents, and of course it works with shell buffers too, this means that if we&rsquo;re using `vterm` and we run a compile command that results in errors then we will be able to jump to the error source just as before, to use this we just need to activate the `compilation-shell-minor-mode`.


<style class="fallback">body{visibility:hidden}</style><script>markdeepOptions={tocStyle:'long'};</script>
<!-- Markdeep: --><script src="https://casual-effects.com/markdeep/latest/markdeep.min.js?" charset="utf-8"></script>
<meta charset="utf-8" emacsmode="-*- markdown -*-">

# Flight Levels vs PMI: The Case for Simplicity in Organizational Project Management
November 6th, 2024
by *Pepe Hernandez*

I am wondering why I am resistant to complex methods. Complexity is a function of the number of elements in a system. The more elements, the more complexity. I like simpler systems. I tend to have low or no trust in complex solutions. The first question is, how can you be sure it will solve your problem? How do you know that without trying the solutions for a certain time? 

Given Gall's Law ""a complex system that works is invariably found to have evolved from a simple system that works".

Why not try first a simple system. 

Eliyahu Goldrati points out that admiration for complexity is an obstacle to good thinking. Love for complexity is bad in this context. If you compare PMI's Organizational Project Management model with Flight Levels, you will detect rapidly the complexity of PMI's approach.

Simplicity is undervalued. Loving complexity creates more intricate systems. Goldratt thinks that simple solutions truly can solve problems. Simpler does not necessarily mean easier. The Flight Levels Model was developed using principles of Systems Thinking, Lean Methodologies, and the Theory of Constraints. 

Steve Jobs said that simple can be more complicated than complex: You have to work hard to get your thinking clean to make it simple. But it's worth it in the end because once you get there, you can move mountains.

As I read the framework, I compared every element of the PMI approach with Klaus Leopold's Flight Levels model. The PMI model includes 10 knowledge areas. Klaus Leopold has three levels and 5 activities for achieving business agility. This simple comparison shows that Flight levels are a simpler model to understand and implement, even though their creation took years for Leopold. He was an advocate and pioneer of the Kanban Method in Knowledge services 14 years ago. 

While comparing the models, I remembered Ockham's principle: "The simplest solution is often the correct one." 

There are some variations of the Ockham principle:
It is vain to do with more what you can do with less.
An explanation of a fact must be just enough.
Lastly, the simple solution is the correct one most of the time.

Flight Levels has fewer elements than the PMI's Organizational Project Management Model. Following the Ockham principle, this solution is more likely to be right.

Another thing that I dislike about the PMI model is that it seems to be a framework for managing a large number of projects. The lean agile principles say that you must limit your Work in Progress to obtain better performance and increase predictability.

Antoine de Saint-Exupéry, Airman's Odyssey: "Perfection is achieved, not when there is nothing more to add, but when there is nothing left to take away." I think Flight Levels is just enough.

As David Anderson pointed out. Being bureaucratic adds value? Certainly not. You use bureaucracy to achieve a goal. You use bureaucracy because it is a means for something else. Why not use a tool that requires less overhead, less time, and fewer resources if you achieve the same with both. 

Less is more.


<style class="fallback">body{visibility:hidden}</style><script>markdeepOptions={tocStyle:'long'};</script>
<!-- Markdeep: --><script src="https://casual-effects.com/markdeep/latest/markdeep.min.js?" charset="utf-8"></script> <meta charset="utf-8" emacsmode="-*- markdown -*-">
# Psychological Safety 
September 23th, 2024
by *Pepe Hernandez*

**How to identify and develop high-performing teams? This article helps us create psychological safety faster, better, and more productively.**

#ThePerfectTeam #PsychologicalSafety #ShowVulnerability #SocialSensitivity #HighPerformingTeam

Rozovsky and her study group at Yale School of Management. Instead of being a support group, it was a source of stress. Everyone was fighting for power. Rozovsky decided to join another group. The new group aimed to analyze real business cases. They immediately clicked. In a competition, they were asked to replace a student-run café. In the end, they decided to create a mini gym with two stationary bikes and three treadmills. They won the competition.

How can two groups be so different—one with a stressful atmosphere, and another warm and fertile for generating ideas?

Traditional productivity studies focus on the individual. However, most work is done in teams. Even more so, in the last 50 years, human interaction has increased by over 50%, occupying 1/3 of work time.

In 2012, Google embarked on the Aristotle Project, studying hundreds of individuals. Rakovsky joined Google as part of the Aristotle Project. There were vastly different patterns in high-performing teams. After a year of analyzing 100 teams, they couldn’t find a clear solution. In the end, they tackled the problem by focusing on psychological safety.

What did they study?

What distinguished good teams was how members treated each other. They found two key characteristics:
- **“Equality in the distribution of speaking turns”**: As long as everyone has the opportunity to speak, it's fine. If one person dominates the conversation, collective intelligence drops.
- **“High social sensitivity”**, meaning members were good at sensing how others felt based on tone of voice, expressions, and other non-verbal cues.

**Tips**: Talk more about emotions and how we feel. Google also keeps statistics on this. Why not spend time with people who care about me?

In these teams, there is greater psychological safety: **“a sense of trust that the team won’t embarrass, reject, or punish anyone.”** Talk to your teammates about difficult or sad things. Speak about insecurities, fears, and aspirations in a more constructive way.

Sakaguchi, a former police officer and electronics salesman, was in charge of successfully coordinating a team of engineers at Google. However, when he switched teams, he didn’t achieve the same results. A satisfaction study revealed that many people were dissatisfied because there was no **TRANSPARENCY** regarding the contribution and role of team members. To break the ice, Sakaguchi revealed he had advanced-stage cancer. Everyone was shocked. How could Sakaguchi still be there in such a condition? It was because of the fulfillment of helping the team.

Today’s winners succeed because they have the clarity to discard yesterday’s conventional wisdom and seek the new and innovative...

**REFERENCES**:  
[https://www.nytimes.com/es/2016/03/16/espanol/la-busqueda-de-google-por-el-equipo-perfecto.html](https://www.nytimes.com/es/2016/03/16/espanol/la-busqueda-de-google-por-el-equipo-perfecto.html


<style class="fallback">body{visibility:hidden}</style><script>markdeepOptions={tocStyle:'long'};</script>
<!-- Markdeep: --><script src="https://casual-effects.com/markdeep/latest/markdeep.min.js?" charset="utf-8"></script><meta charset="utf-8" emacsmode="-*- markdown -*-">

# Requirements elicitation in the Age of AI 
October 4th, 2024
by *Karina Chaires*

One of the greatest challenges in software development has always been defining clear and precise requirements. It is essential to have a thorough understanding of what needs to be built before jumping into the coding process. According to Wiegers[Wiegers](https://en.wikipedia.org/wiki/Karl_Wiegers), a requirement is a specification that describes some functionality, attribute, or quality factor of a software system. It may also describe any constraints on how the system is built.

At first, defining requirements may seem like a simple task, but in reality, poorly defined requirements can lead to significant frustrations and setbacks in a project. There are many well-established methods and a wealth of literature on how to properly manage this process. Below, I'll highlight some of the key requirements that, in my opinion, you should consider.

### Key Requirement Types

**Business Requirements**: These outline the goals of an organization.  

**Business Rules**: Policies, guidelines, or regulations that define or restrict aspects of the business. While not software requirements themselves, they often give rise to various software requirements.  

**Constraints**: Limitations imposed on the options available to developers for designing and building a product.  

**Functional Requirements**: Descriptions of behaviors that a system will exhibit under specific conditions.  

**User Requirements**: Goals or tasks that specific user groups must be able to achieve with a system or desired product attributes.

### Deliverables and Artifacts in the Requirements Process

Once the different requirements have been identified, the next step is to produce a series of deliverables that serve as documentation throughout the project. Some common artifacts generated during the requirements process include:

**Artifacts produced during the requirements process**:

- **Business Requirements**  
 - Background  
 - Business Opportunity  

- **Scope and Limitations**  
 - A table outlining the project's scope and limitations  

- **Business Context**  
 - Customer profiles  
 - Customer priorities  
 - Business model diagram  

- **Design and Documentation**  
 - General system structure  
 - Prototypes  
 - Table detailing functional requirements and constraints  
 - Context diagram  
 - Container diagram  
 - Component diagram  


### Moving Towards the Future with AI

Defining requirements is a process that can be either highly abstract or extremely detailed, but the ultimate goal is to be clear about what needs to be done before executing it. In this new era, where artificial intelligence plays a significant role in all areas, it’s possible that AI will eventually solve this issue, eliminating the need to “read the minds” of stakeholders. That’s something we’ll find out in the future. In the meantime, we must continue applying best practices to develop software effectively.

However, until that time comes, it's important that we continue to apply established best practices in software development. Proper requirement management is crucial for building successful systems that meet both business needs and user expectations.


While tools and methodologies have evolved, the human element remains critical. Clear communication, regular feedback loops, and a deep understanding of business objectives ensure that requirements are not only defined but refined throughout the project's lifecycle. As AI tools begin to assist in automating aspects of requirement gathering, the role of developers and stakeholders will shift towards validating and contextualizing those requirements to ensure alignment with the project's goals. By blending human insight with emerging AI technologies, teams can create more efficient, accurate, and adaptable software solutions that better meet user and business needs.

<style class="fallback">body{visibility:hidden}</style><script>markdeepOptions={tocStyle:'long'};</script>
<!-- Markdeep: --><script src="https://casual-effects.com/markdeep/latest/markdeep.min.js?" charset="utf-8"></script>
<meta charset="utf-8" emacsmode="-*- markdown -*-">


     **A Single Text File Is My Productivity Hack**

October 22nd, 2024
By Alejandro Garcia

We are living in the new dark ages. In the future, when our Cyborg descendants are trying to make sense of the early 2000s
They will have a tough problem finding evidence because files get lost or even more frustrating.
The tools that could read the file.
Stop working.

I'm terrified of storing my notes in file formats that might become obsolete in the next decade.
These are my most private thoughts, a snapshot of my growth.
Maybe they are worthless to the rest of the world, but they are valuable to me.

That is why I type my notes in plain text.
However, having many small files creates challenges with organization, searchability and formating.
So in 2020, when I read this post: [My productivity app is a never-ending .txt file](https://jeffhuang.com/productivity_text_file/)
I was inspired to try it myself.

Being an Emacs and Bash user immediately resonated with me.
So the idea is that you write your notes in a long text file,
and then you need to search for something it's as simple as doing a `grep` of your text file.

What I like about the single-text file method is that it doesn't require anything.
Just open a text file.
Write the date in one line and write your note next to it, and you're done.

However, over the years, I have settled on a couple of "hacks" that make this even better.
My tricks are:

- Use jrnl
- Create a shortcut on your keyboard to add notes.
- Use a variant of the Getting Things Done organization method.

Let's see these tricks.

# Use `jrnl`

[Jrnl](https://jrnl.sh/en/stable/) is a command-line app that formats and searches your text file.

For example, if I have an idea that I want to share with @Agus (he is another member of our cooperative).
I would write in the command line:

``` bash
jrnl Ask @Agus How can I recycle pet plastic for my @3d-printer
```

This instruction will append the following entry in my ~/jrnl.txt file.

``` bash
$ tail -1 ~/notes/jrnl.txt
[2024-10-22 01:20:15 PM] Ask @Agus How can I recycle pet plastic for my @3d-printer
```

As you can see, the current date and time have been prepended to our note.
Now, let's suppose: I'm meeting @Agus in person, and I want to remember everything I would ask him.
The command is:

``` bash
$ jrnl @Agus
┏━━━━━━━━━━━━━━━━━━━━┓
┃  16 entries found  ┃
┗━━━━━━━━━━━━━━━━━━━━┛
2023-09-10 07:07:07 AM @agus about the naked objects pattern, maybe search for
a video example and develop it in Eiffel
.
.
.
2024-10-22 01:20:15 PM Ask @Agus How can I recycle pet plastic for my
@3d-printer
```

Observe that the search is case insensitive, so it will return me entries with @Agus and @agus equally.
We can search by either having one OR two tags:

``` bash
$ jrnl @agus @nohemi
┏━━━━━━━━━━━━━━━━━━━━┓
┃  18 entries found  ┃
┗━━━━━━━━━━━━━━━━━━━━┛
```

Also, we can search by entries that have both tags (and).

``` bash
$ jrnl @agus -and @3d-printer
┏━━━━━━━━━━━━━━━━━┓
┃  1 entry found  ┃
┗━━━━━━━━━━━━━━━━━┛
2024-10-22 01:20:15 PM Ask @Agus How can I recycle pet plastic for my
@3d-printer
```

We can also search by date.

``` bash
$ jrnl -on 2024-10-22
┏━━━━━━━━━━━━━━━━━┓
┃  1 entry found  ┃
┗━━━━━━━━━━━━━━━━━┛
2024-10-22 01:20:15 PM Ask @Agus How can I recycle pet plastic for my
@3d-printer
```

We can see what tags we have:

``` bash
$ jrnl --tags
┏━━━━━━━━━━━━━━━━━━━━━┓
┃  526 entries found  ┃
┗━━━━━━━━━━━━━━━━━━━━━┛
@racket-con          : 31
@ideas               : 25
@til                 : 23
...
```

You can run all those commands and get even Json, and then use other tools like `jsonata` or `jq` to do some further processing.

``` bash
$ jrnl @agus -and @3d-printer --format json
┏━━━━━━━━━━━━━━━━━┓
┃  1 entry found  ┃
┗━━━━━━━━━━━━━━━━━┛
{
"tags": {
"@3d-printer": 1,
"@agus": 1
},
"entries": [
{
"title": "Ask @Agus How can I recycle pet plastic for my @3d-printer",
"body": "",
"date": "2024-10-22",
"time": "13:20",
"tags": [
"@3d-printer",
"@agus"
],
"starred": false
}
]
}
```

All in all, `jrnl` has been the most user-friendly way to keep a long text file as my notes document.

# Create a keyboard shortcut

My next hack is to create a shortcut that opens your text editor with the notes file already opened with a text line.
You can ask ChatGPT how to do this for your operating system.

## Create a script to open the text file

In my case, using the Ubuntu operating system with the `gedit` text editor is as simple as:
creating a script `nano ~/append_datetime_to_jrnl.sh`

``` bash
#!/bin/bash
# Script to append the current date and time to jrnl.txt and open it in gedit
current_date_time=$(date "+%Y-%m-%d %H:%M:%S")
echo "$current_date_time" >> ~/notes/jrnl.txt
gedit ~/notes/jrnl.txt
```

Then make the script executable: `chmod +x ~/append_datetime_to_jrnl.sh`

## Assigen a the script to a keyboard Shortcut

Go to Settings -> Keyboard -> Custom Shortcuts.
Click Add Shortcut.
Set the Name to something like Append Date/Time to Journal.
In the Command field, enter the path to your script:
bash
Copy code
/home/your-username/append_datetime_to_jrnl.sh
Replace your-username with your actual username.
Set the desired keyboard shortcut by pressing the keys you want to use (e.g., Ctrl + Alt + J).
Click Add.

# Using the Getting Things Done method
Finally, the GTD method, popularized by David Allen, has many techniques for organizing oneself.
However, the core of the method is to have several lists of activities depending on the context.
for example an

@home
: is to write things that you intend to do when you are at your home

@agus
: is to write lists of things you want to discuss when seeing Agus.

@email
: to write emails that you would like to write.

@some-day
: is to write projects or dreams you would like to tackle someday.

As we have seen with `jrnl`, it is straightforward to implement all of these lists as a single text file with tags.

# Bonus tip: I Love Me list

My friend and supervisor, Paul M. Jones, taught me to keep the @I_love_me list.
The idea is to write down your accomplishments, personal and professional.
This list is essential.

Sometimes, we are sad and need a little shot of our "self-esteem."
It's just a matter of writing `jrnl @I_love_me` and reading about the things we have done in the past to find perspective.

The list also has a professional value.
When is time for your yearly review at work.
And you need to remember your accomplishments is as simple as:

``` bash
jrnl @I_love_me -and @work -from 2024-01-01 -to 2024-12-31
```

# Conclusion

A simple text file, with `jrnl` and some habits inspired by the GTD, has been my best note-taking application.
This method will continue to work in the next 40 years.
Or when it's time to merge our conciousness with the great computer in the sky, I'll have my notes ready ;-)

<style class="fallback">body{visibility:hidden}</style><script>markdeepOptions={tocStyle:'long'};</script>
<!-- Markdeep: --><script src="https://casual-effects.com/markdeep/latest/markdeep.min.js?" charset="utf-8"></script>
<meta charset="utf-8" emacsmode="-*- markdown -*-">

# The billion dolar Code. A Netflix series about code infringement. The case of Terreavision and Google Earth.

Octuber 20th, 2024
By Pepe Hernandez

In 1993, in Berlin, an artist (Pavel Mayer or Yuri in the series) and a hacker (Joachim Schlüter, portrayed as Carsten in the series) came together to create software ahead of its time: TERRAVISION. This project allowed users to navigate the globe and zoom in to get a physical view of a location. The interface for selecting and navigating to the desired place was a sphere. To develop it, they partnered with one of the largest companies in Germany, Deutch Post, now Deutch Telecomm. The project brought together a group of hackers and designers who created an interface that preceded Google Earth by eight years. The ART+COM project came before Google's, which wasn’t publicly released until 2001.

In 2014, ART+COM filed a lawsuit against Google, accusing it of infringing the 1995 TERRAVISION patent with its Google Earth software, published in 2001. In May 2016, a U.S. District Court jury ruled in favor of Google, arguing that there was prior publication before the patent registration in 1994, referring to a geographic visualization system called "SRI Terravision." SRI stands for Stanford Research Institute. The jury asserted that "Art+Com could not prove its patent infringement claim because the patent was anticipated by the public prior to the December 1995 priority right claim."

In the story, the two German hackers visit Silicon Valley. Astutely, the Chief Engineer (Warren Stuart, a fictional character) at Silicon Graphics is impressed with what Pavel and Joachim have accomplished. The engineer invites Joachim (the hacker). Thanks to the mutual admiration and connection between Joachim and Warren, Warren confesses the full operation of their invention to him, something he would regret years later. In 2001, when the company is still working on its project in Germany, they discover that Google had overtaken them and that Warren had stolen their idea. This part of the series is fictional but highlights the importance of protecting intellectual property before sharing it publicly.

One of the conclusions hinted at in the miniseries is that proving a software program has been plagiarized is always a challenge in courts around the world. There are many similarities in software features, companies are reluctant to show their complete code, and it’s difficult to find court experts with the expertise necessary to understand the code.

In general, various reviews and opinions about the miniseries discuss how it’s almost impossible to win legally against a company as large and resourceful as Google, even if you are right. As a final note, Google’s intellectual property manager attempted to purchase the patent from ART+COM prior to the release of Google Earth. The negotiation was unsuccessful. ART+COM was left without the project, with an invalidated patent, and without the economic benefits of the patent.

P.S. The key article was called Terravision, and ART+COM's project trademark was also Terravision. Why? Was there a relationship between ART-COM's Terravision and SRI's technical note? We will never know.

Key intellectual property concepts identified in the series:

There are two key elements of intellectual property: hardware and software.
The hardware was represented by the interface used to navigate TERRAVISION. In the miniseries, the interface designer tests many alternatives before deciding on a globe to navigate the application.
The software, the core of the system, consisted of an algorithm that allowed maps to load gradually instead of all at once, in packets of 128 kilobits (the size of the memory). There was also a new floating coordinate system, which is the basis of current geographic information systems (GIS).
There is a third element of intellectual property: the maps themselves, which were obtained from various sources. The miniseries doesn’t delve into or criticize how these maps were obtained, but ART+COM had all the maps available at the time to make their project possible.

Personal reflections on how intellectual property influences...

Several key conclusions can be drawn from the provided summary regarding the context and implications of the case between ART+COM and Google related to Terravision:

- **ART+COM was an innovative company ahead of its time.** The Terravision project, developed in the year they built the prototype presented at the Kyoto fair, demonstrated the functionality that Google Earth would display years later. Technological innovation can be ahead of its time. In this context, it is crucial to be aware of the inherent risks in protecting intellectual property in emerging industries, such as Geographic Information Systems (GIS) in this case.
- **Legal complexity of intellectual property in the software industry.** ART+COM was unable to adequately protect its patent due to the existence of prior art (the SRI visualization system publication), which highlights how early disclosure of an innovation can prevent companies from obtaining later legal protection, even if they were pioneers in their field.
- **Proving software plagiarism in court is difficult.** The case reflects one of the significant barriers in software infringement lawsuits: demonstrating that a software program has been plagiarized is complicated due to the technical nature of software, the difficulty in accessing source code, and the lack of judicial experts specializing in understanding and comparing functionalities.
- **The economic power of companies matters in litigation.** The case also exposes a critical point discussed in the miniseries: it’s difficult, if not impossible, to legally compete against tech giants like Google. Even if you are right, the access to massive legal and financial resources by large corporations can tilt the scales in court.
- **Several key intellectual property elements related to software.** The hardware (user interface) and software (map-loading algorithms and coordinate systems), as well as maps obtained from various sources, formed the complete globe exploration system. Legally protecting each element separately and together is complex.
- **An intellectual property manager was necessary.** There should have been someone proactively responsible for this task. Just as a financial manager was designated in the series, there should have been someone assigned to handle intellectual property.
- **The judicial system is prone to bias.** The perception that one cannot defeat a company like Google, regardless of the merit of the case, reflects a broader critique of the judicial system in intellectual property cases, where size and financial resources play a determining role in outcomes. This presents a challenge for small entrepreneurs in emerging industries.


<style class="fallback">body{visibility:hidden}</style><script>markdeepOptions={tocStyle:'long'};</script>
<!-- Markdeep: --><script src="https://casual-effects.com/markdeep/latest/markdeep.min.js?" charset="utf-8"></script> <meta charset="utf-8" emacsmode="-*- markdown -*-">
# The Rise and Fall of Abacus Rationale
September 18th, 2024
by *Pepe Hernandez*

Abacus Rationale started small. It started from a software entrepreneurship effort in the eighties. A teacher developed a payroll system for their university, which was a success. He continued his career at the university as a teacher and obtained great credibility for his achievements, but he wanted to be an entrepreneur.

The entrepreneur wanted to create a company and was associated with a finance and accounting specialist, and both made the Abacus Rationale. Together, they envisioned the first company service:  Internet Subscription. They offered a product different from the one provided by the telecommunications monopoly in Mexico. The users started to grow and grow. A pair of years later, the service had 10,000 active accounts. As a small company trying to diversify its services, it sold equipment and repaired computers. That was before the big companies started to offer high-band internet services. When the Mexican telecommunications market opened to competence, there was both a there and an opportunity. New entrance companies began to buy small companies' user base. Abacus Rationale saw that as an opportunity and sold theirs to one of the big three internet providers. There were two options: trading and getting some money or slowly losing their user base. Abacus Rationale sold, and rethink the road ahead.

That was a good move. It allowed Abacus Rationale to make good money and specialize in selling equipment and IT infrastructure solutions to its main customer, the Local Government.

The company went from software development to subscription services and then to retail and IT solution provider in the middle of the 1990s.

## 1990s

During that period, Abacus Rationale hired several engineers and invested heavily in them. The company paid the engineers well, and they received annual bonuses. They also received a very flexible day job schedule. They could work anywhere. The entrepreneur adapted to new times.

The physical office was a house of three levels: the medium, the basement, and the upper. The rooms of the house were offices for the different teams: accounting, selling, engineering, and monitoring. They had a meeting room, a reception, and a hall with several desks. The Engineers guys were good at their craftmanship. They became better due to the policy established by the entrepreneur. They had the time to study all the equipment and simulations to learn how to configure the different appliances. The agreements with the big TelCo providers had the benefit of asking for new equipment and virtual training for "free." Engineers had at hand routers, phones, switches, virtual simulators, and several artifacts to make experiments. When the engineers were confident, they asked management for money to pay for a certification exam. The company didn't invest in training classes, workshops, or courses, but Abacus Rationale made a big difference—the company had more certifications than all the local companies. On average, every engineer had more than eight certificates.

The engineers' experience, validated by their official achievement certificates, was a strong differentiator when the government or other clients asked for service from local companies. The infrastructure solutions and the quality of their structured cable, fiber, routing, IP telephony, LAN configuration, and LAN security were of higher quality.

The entrepreneur was a native seller. He makes the right deals. The company always had Projects.

They also grew in personnel slowly. Just enough to continue their sustained growth.

## The 2000s

The oil bonus of 2000 provided many resources from the Mexican local government until 2010. The property allowed investment in the modernization of government services and facilities. From 2008 to 2010, a big budget was allocated to developing government facilities, infrastructure, and digital services. Abacus Rationale had the relational capital, the knowledge capital, and the financial support to take a good piece of cake. They made it.

Abacus Rationale was a certified partner of the Big Guys. Other companies with financial support and knowledge made their offers but didn't know the context very well. Abacus Rationale knew what government agencies needed. Abacus rationale knew the context well on their own and their insiders on the government.

Abacus had the muscle, experience, knowledge, backup, and relationships and had grown enough to be financially supported by the big telco communication equipment companies.

That was good and prosperous times.

Abacus Rationale has created many good relationships with its clients due to its professional services and frequently because of its patients. Sometimes, the government doesn't pay as fast as the contractors need.

## The 2010s

In 2010, things started to change. There was a change of administration. New times, in context, require different policies. The federal government began limiting equipment length and changing the contract services policy. Selling equipment was one of their primary sources of income. Instead of buying computers, leasing was an option for the government to have good computers.

But there were other opportunities to take advantage of. The federal and local governments continued believing in innovation and the digitalization of services. They also supported entrepreneurship and invested in people's digitalization culture.

Abacus Rationale had prestige and was open to new ideas.

Federal government funds were available for companies, organizations, academia, and governments to support innovations and entrepreneurship projects. That was the case for InnovaPYME and ProSoft (federal programs created with this aim).

Before 2010, other actors arrived: Research Centers, Top Public Universities, a young wave of technopolitics, and new small companies that wanted to make a dent in the local universe and take advantage of all the existing funds. Both the InnovaPYME and ProSoft programs motivated collaboration between Academia and Private Companies.

Abacus Rationale started collaborating with a research center specializing in software projects to create a spinoff in its successful IT service provider vein. In 2012, a small software company was made—in reality, it was a startup. The SW company was looking for a business model. The company was named Code Rationale, following its parent's Rational way of work.

The Research Center had grouped a very talented bunch of people, some coming from booming government pace, others from industry, and persistent entrepreneurs with previous startup adventures scars.

Abacus Rationale, in collaboration with the Research Center, created Code Rationale. The Research Center used all its expertise to hire and train the development team, which a proficient Architect and Developer led. The team developed transactional software using the best open-source tools, frameworks, and base language. They had a year to create four prototypes, and they did it—even though they were looking for a business model.

After the first year, Abacus Rationale found a promising bet: Business Process Digitization Services. One year after the company's creation, Code Rationale started to offer another digitization service and a software house for transactional government systems. They also received funds from InnovaPYME and created both software and hardware to specialize in document digitization.

At the same time, there were software development projects with other government organizations. Code Rational's team had to grow. They started with less than ten people. In three years, the developers' team was threepled.

Meanwhile, the projects for Abacus Rationale started to slow down. Cloud Web Services were a precarious competence, but a real one, for physical sites. The government doesn't use Cloud Web Services at all today, but some of the big entities do.

The local government promoted an Innovation Park where all innovative companies could create research centers. The Federal Government wants all Mexican states to have their innovation parks. The Local Government invited Innovative companies to join the effort. It was challenging to say no. The government was still the primary customer of Abacus Rationale. It was like a Trojan Horse. It was like a poisoned apple.

Abacus Rationale compromised its future to build the headquarters of its dreams. They did it; it was a big bet. The luxury building could be the company's presentation card.

Then, the country's economic context changed dramatically. Local states started to need more resources. That was 2018. The New Federal Administration erased innovation funding programs and other funds for specific purposes; the Federal Government erased municipal development funds, mining funds, and disaster funds. All were concentrated at the federal government level to invest in social programs for younger and third-age people. What innovation companies did some companies take advantage of to grow and disappear in just one year?

Then, the COVID-19 pandemic hit the world and the economy.

## The 2020s

In 2021, there was a radical change in the Local Government from a different party.

Abacus Rationale started to starving. No projects, no money. Depending mostly on one client made Abacus Rationale fragile. The little brother of Abacus was an instrument for selling.

From 2012 to 2018, Code Rationale was Net Profitable. But the pressure was too high. Code Rationale received the work and the problems, but it didn't receive the benefits of the Abacus projects obtained thanks to the Code Rationale sacrifice.

In 2018, Code Rationale gave up.

When Toyota faced the challenge of the global crisis in 2008 and then the recall crisis in 2010, it was prepared. It had a global market, the TPS, the culture, the people, and leadership. It took advantage and refocused on quality again. Abacus Rationale could have had the same opportunity.

When 3M faced a mining crisis, it gave the employees time to look for new ways to make money. That allowed the creation of different projects, among them the Post-it. Abacus Rationale could have the time.

But Abucus Rational had no money.

## Lack of money = lack of time

They needed money but a new luxury headquarters in the Innovation Park.

After investing in the new headquarters building, all the money was used to pay, so the annual bonus disappeared completely. That started in 2018.

The company, which had evolved resiliently from software to a subscription service, IT infrastructure solutions, and business process outsourcing, lost its direction.

Entrepreneurs thought that a building could be the prestige they needed to go further.

Without new projects, an important part of the personnel payroll disappeared. The personnel had to look for new projects. The few projects were assigned to other providers. Each new Government administration has its preferences, under the legal boundaries. That was the case.

The engineers left the ship one by one until the last proficient engineer left the dream.

The entrepreneurs who invest "a lot" of money in the certifications ask them to stay—to hold on. But more mature people need money to cover their normal expenses (household, food, tuition, etc.). They look for new jobs, and they find them.

All the certified engineers now work for more prominent companies. Their experience, knowledge, and certificates went with them in their hearts, brains, and bodies.

The entrepreneur, his finance associate, and a pair of clerical people stay in the company, and they rent offices in the building they thought would once be the leverage point for the company's growth.

## What might have been?

What could have happened if the entrepreneur hadn't invested in the building and could have done what Toyota or 3M did to overcome the difficult times? As Eliyahu Goldratt, the creator of the Theory of Constraints, said: You have to take advantage of any crisis. Why did they not make a decision that made them a little bit antifragile or at least gave them more options for the future? We'll never know. The "would" does not exist.

<style class="fallback">body{visibility:hidden}</style><script>markdeepOptions={tocStyle:'long'};</script>
<!-- Markdeep: --><script src="https://casual-effects.com/markdeep/latest/markdeep.min.js?" charset="utf-8"></script>
 <meta charset="utf-8" emacsmode="-*- markdown -*-">
# Understanding complexity in software systems

September 23th, 2024
by *Julio César*

> Controlling complexity is the essence of computer programming.
> 
> — Brian Kernighan

Recently I&rsquo;ve been enjoying reading &ldquo;A philosophy of software design&rdquo; by John
Ousterhout, the main focus of the book is to learn techniques to reduce
complexity in a software system and use that to drive our design decisions.
Before diving into how to reduce software complexity we might ask, what is
complexity?

Complexity in software is a term that has been explored a lot, I would think
that since we as a society started to depend on software systems to replace
processes that didn&rsquo;t need computers before, we started to observe a toxic pattern
emerging on our code bases.

Software systems never seem to be complete - they seem to always require
changes to be made - so systems have a need to be maintained. However, over
time, the system starts to rot, modifications become harder and harder to
make, this is the main indication of having a complex system in sight. Fred
Brooks wrote something on complexity in his famous book &ldquo;The Mythical
Man-Month: Essays on Software Engineering&rdquo; - from his perspective, there are
two kind of complexities, first, *essential complexity* - the kind of complexity
that exists just because the domain a software models maps to is inherently
complex. The second type of complexity Brooks writes about is *accidental
complexity* which is more in line with the notion of complexity that Ousterhout
documents in his book.

Accidental complexity is what remains when we take essential complexity out of
the picture, it is often the result of lack of skills, bad habits software
developers adopt, or frequently, simply due to an incomplete understanding of
the domain and the problem we are trying to solve. Under Ousterhout&rsquo;s
framework complexity is anything that inhibits change on a software system and
is primarily a consequence of bad software design decisions (be it small or
big) made one after another during a continuously prolonged amount of time. It
is hinted that software complexity is something that can&rsquo;t just be avoided at
all and will always exist but there are practices that help software
developers to manage it.

According to Ousterhout it is paramount to train ourselves to identify
complexity, we cannot start to manage it if we cannot see it in the first
place! In the book we&rsquo;re taught that one way to see complexity is to identify
where in the system we&rsquo;re spending the most time working on, typically, the
more time necessary to change a certain component of a system will hint that
the component is harder to change and therefore complex.

One might also think that beyond time - size of a component is also a good
indicator for presence of complexity in a system, yet this is not true, big
systems aren&rsquo;t necessarily complex, if they are easy to work with then they
remain simple. On the contrary, there could be pieces of code or even a single
instruction that on its own is very hard to understand and change, what is
worse is that in some cases doing the change might impact other parts of the
system unexpectedly, so beware! complexity can hide even behind a single line
of code.

Ousterhout mentions three signs that alert the presence of complexity in a
code-base.

1.  Change amplification
2.  Cognitive load
3.  Unknown unknowns

In the first case, whenever the implementation of even the simplest feature needs
a lot of changes in lots of places of the system it is said we&rsquo;re
suffering of *change amplification* and it is a major *major* sign of accidental
complexity on a software system.

On the second case, whenever the developers need deep understanding of a lot
of context in the code-base to carry out a simple change then *cognitive load*
exists. It follows then that lines of code do not translate to code
complexity, it may be the case that simple changes require lots of lines of
code - or, on the contrary, a complex change could end up being just a single
line change. Cognitive load refers about the context the developer needs to
understand in order to make changes to the system, the bigger that context is
the more complex the system is considered to be.

The third case, &ldquo;Unknown unknowns&rdquo; is a sign of complexity where a developer
doesn&rsquo;t know what or where a change is required to implement a certain
feature; often developers follow a hunch on what needs to be modified to get
the job done, they try out the new feature thinking all is done but then as
soon as it is tested the behaviour reveals the change is incomplete, there&rsquo;s
something the developer didn&rsquo;t anticipate and doesn&rsquo;t understand why the
change they made wasn&rsquo;t sufficient - &ldquo;Why it isn&rsquo;t working yet if I have just
changed this part here?&rdquo;, that&rsquo;s an unknown unknown.

From all the signs of complexity in a software system, having unknown unknowns
is the worst, it reveals deep problems in the design of the system as it is
non-obvious what its structure is and there&rsquo;s no clear path to evolve it in a
sane way.

All in all, these are just signs that we have a complex system in our hands,
but it doesn&rsquo;t give indication of where that complexity is coming from or how
we can tackle it. Ousterhout suggests that complexity is mainly introduced by
*dependencies* and *obscurities* in a software system.

Dependencies exist whenever
the code can&rsquo;t be understood in isolation, or, when changes in a part of the system
also require separate components to be updated, there we have a
dependency.

Obscurity is another form of dependency, but is a non-obvious one, or rather
an indirect dependency where there&rsquo;s nothing in the code that relates two
areas of the code-base that in reality are coupled to each other. Obscurity,
also happens when a variable or symbol refers to two separate concepts, in
this case, there&rsquo;s a dependency but it isn&rsquo;t clear what that dependency
entails or what is affected by changing it. A simple example may be a numeric
variable whose type (or name) does not hint about the &ldquo;units&rdquo; of the value
stored in that variable, e.g. 42 centigrade isn&rsquo;t the same as to 42 minutes. Also,
whenever we need extensive documentation on a component, whether in the code
or outside of it, we can take this as a clear indication that we have
obscurity in the code, or else, what&rsquo;s the need to explain it so thoroughly?

This is a good point to stop our exploration on software complexity, and as
we&rsquo;ve seen complexity is a key aspect to account for if we want to end up with
simpler and maintainable systems; if we can find ways or design techniques
that minimize dependencies and obscurity in our code-base then we&rsquo;ll be able
to reduce the complexity of the system as a whole. In a future post we&rsquo;ll
understand more about both of these aspects of software, and in doing so we&rsquo;ll
be able to come up with good software design decisions that over time will
help us rather than fight against us.


<style class="fallback">body{visibility:hidden}</style><script>markdeepOptions={tocStyle:'long'};</script>
<!-- Markdeep: --><script src="https://casual-effects.com/markdeep/latest/markdeep.min.js?" charset="utf-8"></script>
<meta charset="utf-8" emacsmode="-*- markdown -*-">

# Unlocking the Power of Personal Cloud
September 24th, 2024
by *Agus Rumayor*

Rent vs Buy is a well-known dilemma, and we have plenty of tools and calculators to help us decide one of the biggest financial questions in life. From comparing the cost of buying versus renting to weighing opportunity costs like capital gains versus investment profits, there's one clear spoiler: if you plan to stay in one place for more than 10 years, it’s generally better to buy.

For data engineers, we face a similar dilemma: should we "rent" cloud services or "buy" our own? From a financial perspective, the conclusion is pretty much the same. If you plan to manage your data or services in the long run, it’s worth considering "buying" your own cloud.

That’s where the personal cloud comes into play, a solution that offers not just storage, but also long-term control, security, and savings in your data services. Rather than renting space on third-party servers, a personal cloud involves hardware you control. Setting up a personal cloud isn’t as simple as signing up for a public cloud service. It requires a bit more technical know-how and upfront planning. However, for individuals or small businesses that need large amounts of storage, prioritize data privacy, or want to avoid recurring costs, personal cloud storage could be the perfect long-term solution.

## What is needed?

A personal cloud should be tailored to meet your unique needs. From a developer or techie perspective, we aren't just talking about storing typical personal data like photos and documents. We need a robust environment that allows us to experiment, test, and host applications. Think of it as your personal sandbox, an all-in-one space for cloud data storage, cloud computing, hosting files and apps, and security tools to manage all these services.

Let's start with essential services:

************************************************************************
*                                                                      *
*               │                                                      *
*               │                                                      *
*  ┌────────────▼──────────────────┐                                   *
*  │                               │                                   *
*  │         Router                │                                   *
*  │                               │                                   *
*  │                               │                                   *
*  └────────────┬──────────────────┘                                   *
*               │                                                      *
*  ┌────────────▼──────────────────┐   ┌──────────────────────────┐    *
*  │                               │   │                          │    *
*  │  Reverse Proxy / Firewall     │   │    Access proxy          │    *
*  │                              ─┼───┼►                         │    *
*  │ Reverse proxy and firewall    │   │ Proxy to auth users and  │    *
*  │ rules to access all internal  │   │     proxy services       │    *
*  │           services           ─┼───┼─┐                        │    *
*  └──────────────┬────────────────┘   └─┼──────────┬─────────────┘    *
*                 │                      │          │                  *
*  ┌──────────────┼──────────────────┐  ┌┼──────────▼──────────────┐   *
*  │              ▼                  │  ││                         │   *
*  │                                 │  │▼ K8s and docker services │   *
*  │     NAS Private services        │  │                          │   *
*  │                                 │  │  Services allocated in   │   *
*  │  All the services we don't want │  │  private servers         │   *
*  │    to expose                    │  │                          │   *
*  │                                 │  │                          │   *
*  └─────────────────────────────────┘  └──────────────────────────┘   *
*                                                                      *
************************************************************************

### The Key Components
* **Router**

Acts as the entry point for all external traffic coming into the network. The router handles the distribution of incoming requests to the reverse proxy.

* **Reverse Proxy & Firewall**

The reverse proxy is a key component in securing the internal services. It handles external requests and forwards them to either public-facing services or routes them to an Access Proxy for authorization before exposing internal services. The firewall is configured to allow traffic based on specific rules, ensuring that only authorized traffic passes through to the services.

* **Access Proxy**

The access proxy manages Single Sign-On (SSO) and enforces authentication before allowing users to access private resources. When a request is made to a subdomain like private.example.com, the reverse proxy routes it to the access proxy, which authenticates the user and determines access rights.

* **NAS Private Services**

For all data and services that doesn’t need to be publicly exposed, the NAS (Network-Attached Storage) solution serves as a secure, private repository. This is where you store personal data like photos, documents, and any files that don’t require external exposure. Popular NAS devices offer a powerful combination of storage, security, and backup solutions.

* **Kubernetes and Docker Services**

These services power cloud computing and application hosting. K3s, a lightweight Kubernetes distribution, provides orchestration for containerized applications, allowing for easy scalability and management of services like blogs, development environments, or experimental code bases.
Portainer simplifies the management of these containers, providing an easy-to-use GUI for container orchestration, while Coder offers an IDE and development environment in the cloud for collaborative or remote projects.

## Architecture in Action

Let’s break down a real-world scenario to illustrate how this architecture functions.

Public Requests (e.g., public.example.com): When someone accesses a public-facing service like your personal blog, the request hits the reverse proxy, which redirects the traffic to the appropriate internal service (e.g., a Docker container hosting your blog).

Private Requests (e.g., private.example.com): For private services like a personal dashboard or sensitive data, the request is handled differently. The reverse proxy directs the traffic to the access proxy, which requires the user to authenticate via SSO before allowing access. If authenticated, the proxy routes the user to the service behind the firewall.

## Technologies Behind the Setup

Here's a quick summary of the technologies that power each part of my personal cloud:

***********************************************************
*                                                         *
*    ┌──────────────────────┬────────────────────────┐    *
*    │                      │                        │    *
*    │Service               │   Technology           │    *
*    ├──────────────────────┼────────────────────────┤    *
*    │                      │                        │    *
*    │Reverse Proxy         │   Nginx Reverse Proxy  │    *
*    │                      │                        │    *
*    │Access Proxy          │   Teleport             │    *
*    │                      │                        │    *
*    │NAS Private Services  │   QTS (QNAP)           │    *
*    │                      │                        │    *
*    │K8s Docker Services   │   K3s                  │    *
*    │                      │   Portainer            │    *
*    │                      │   Coder                │    *
*    │                      │                        │    *
*    └──────────────────────┴────────────────────────┘    *
*                                                         *
*                                                         *
*                                                         *
***********************************************************

## Why This Setup?

1. **Security**: By using a reverse proxy and access proxy combination, this setup ensures that only authorized users access private resources, while public resources remain easily accessible.
2. **Scalability**: With Kubernetes (K3s) and Docker, you have the flexibility to scale your cloud services quickly as needed.
3. **Cost-Effective**: Thanks to modern tools and open source projects solution offers high performance at a lower cost than traditional enterprise solutions.

<style class="fallback">body{visibility:hidden}</style><script>markdeepOptions={tocStyle:'long'};</script>
<!-- Markdeep: --><script src="https://casual-effects.com/markdeep/latest/markdeep.min.js?" charset="utf-8"></script>
<meta charset="utf-8" emacsmode="-*- markdown -*-">


     **My Dozen Problems**

October 29th, 2024
By Alejandro Garcia

> "You have to keep a dozen of your favorite problems constantly present in your mind,
> although by and large they will lay in a dormant state.
> Every time you hear or read a new trick or a new result,
> test it against each of your twelve problems to see whether it helps.
> Every once in a while there will be a hit, and people will say,
> 'How did he do it? He must be a genius!'"
>
>      -- Richard Feynman, as recounted mathematician Gian-Carlo Rota


What Feynman calls a Dozen problems,
I call my multi-annual obsessions.

There are topics / problems that continuously go back and forth in my head.
Those ideas sometimes decide to visit me at night
and when that happens,
I know the night is lost.
I'll spend hours trying to dissect the problem, back and front up and down.

On the other hand Steven Pressfield on his book: "The War of Art"
says that as Plato identified there is the world of Ideas,
the world of perfection.
And from that world the Muses (magical beings)
whisper into our ears what exist in this perfect world
So that we can create it in this physical world of ours.

But the Muses don't pick only one human.
On the contrary, they whisper to many of us.
And some have the sensitivity to listen to them.
some less have enough skill in their craft (music, poetry, etc.)
to be capable of actually implementing what the Muse inspire us to accomplish.


I suspect this is my case,
I can listen to the Muse,
but my skills are not good enough to actually,
translate that inspiration into something that exist in the world.

But that doesn't matter
I continue to practice,
Who knows, maybe one day
I'll be skilled enough.

So without further ado, let me share the problems that keep we awake at night.
Plus some tools that always help me to try to solve them.

# Problems

## Different perspectives for the same information
: I love this image:

    ![multiple persepectives](./shadow_cube_cas.jpg)

	It shows that the same object can be seen from multiple perspectives.

	Or in programming terms we can show the same data in multiple views.
	We can see a table, or a graph.
	We can see a Tree, or Kanban board.

## Other problems

* How to have successful software company?

* How to teach software project management?

* How to mix a virtual and physical kanban board?

* How can we automate natural construction

* How to automate processes in particular government processes?

* What is proper setup for working with computers (ergonomics) ?

* How can we make software documentation that works all the time?

* How can we have better alignment, between all the layers of software development?

* How to live comfortably in a small house or apartment?


In the coming days, I’ll expand on each of these problems and dive deeper into the tools and approaches I’ve found useful.

## What about you?

If you have a “dozen problems” that keep you awake at night or tools that help you tackle them,
I’d love to hear your thoughts.
Maybe together, we can find new angles to approach these challenges.


<style class="fallback">body{visibility:hidden}</style><script>markdeepOptions={tocStyle:'long'};</script>
<!-- Markdeep: --><script src="https://casual-effects.com/markdeep/latest/markdeep.min.js?" charset="utf-8"></script>
<meta charset="utf-8" emacsmode="-*- markdown -*-">


    <u> **Dive into Faust: The DSL for Musicians and Sound Wizards** </u> 

November 2th, 2024
By Ruben Mevy

 Faust, short for Functional Audio Stream, is a domain-specific language (DSL) crafted for real-time signal processing and sound synthesis. Born in the GRAME-CNCM Research Department, Faust shines with its knack for generating high-performance audio apps and plugins across various platforms. For musicians and sound designers, Faust is a perfect mix of simplicity and power, making it a go-to tool for creating innovative sounds and effects.

## **Why Musicians love Faust?** 

1.**Real-Time Audio Magic**: Faust is a pro at real-time audio processing, letting musicians whip up and tweak sounds on the fly. This is a game-changer for live gigs and interactive setups where instant feedback is a must.

2.**Top-Notch Performance**: The Faust compiler turns DSP specs into super-optimized code for targets like C++, WebAssembly, and more. This means your audio apps run smoothly, even on devices with limited resources.

3.**All-Rounder**: Faust isn't just for music. Its solid signal processing chops make it perfect for crafting sound effects for movies, video games, ads, and other multimedia projects. This opens up a world of creative possibilities for sound designers and composers.

4.**Rich Libraries**: Faust comes packed with libraries full of pre-built functions for common DSP tasks. These can speed up your development process, letting you focus on the fun, creative side of sound design.

## **A Bit of History.** 

Faust was created to meet the need for a high-level language that simplifies the creation of complex audio processing algorithms. Its journey began in the early 2000s when the GRAME-CNCM Research Department started exploring functional programming for audio applications. Over the years, Faust has grown into a mature and widely-used DSL, backed by a lively community of developers and researchers.

## **Getting Started with Faust** 

New to Faust? Here are some tips to kick things off:

1.**Check Out the Docs**: The Faust documentation is packed with guides and tutorials to help you get the hang of the language. Start with the Quick Start guide to see what Faust can do.

2.**Try the Online IDE**: Faust offers an online Integrated Development Environment (IDE) where you can write, test, and compile Faust code right in your browser. It's a great way to play around with the language without installing anything.

3.**Join the Community**: Get involved with the Faust community through **forums**, **mailing lists**, and **social media**. It's a great resource for getting help, sharing ideas, and staying up-to-date with the latest news.

4.**Experiment with Examples**: The Faust website has loads of examples of DSP algorithms and applications. Studying these can give you ideas on how to structure your own projects and make the most of Faust.

In a nutshell, Faust is a powerful and versatile DSL that lets musicians and sound designers push the boundaries of audio creativity. Whether you're looking to create new musical instruments, design immersive soundscapes, or develop cutting-edge audio effects, Faust has the tools and flexibility to bring your ideas to life.








<style class="fallback">body{visibility:hidden}</style><script>markdeepOptions={tocStyle:'long'};</script>
<!-- Markdeep: --><script src="https://casual-effects.com/markdeep/latest/markdeep.min.js?" charset="utf-8"></script>
<meta charset="utf-8" emacsmode="-*- markdown -*-">
<meta name="author" content="Alejandro Garcia">
<meta name="description" content="Is there a silver bullet to solve any and all problems?"
<meta name="keywords" content="triz, toc, ibis, problem_solving">
<meta name="robots" content="index, follow">
<meta name="language" content="English">

<!-- Open Graph meta tags for better social media sharing -->
<meta property="og:title" content="How to define problems">
<meta property="og:description" content="Is there a silver bullet to solve any and all problems?">
<meta property="og:image" content="https://example.com/image.jpg">
<meta property="og:url" content="https://example.com/page-url">

                            **How to define problems**

We all have problems; they are everywhere and at every time.
So, how could we better solve problems?
Is there a silver bullet to solve any and all problems?

I think there is.



# Introduction
==============================================================================

Turns out that we know how to solve all the problems better:

> To ask the right question is already half the solution to a problem.
> Carl Jung.

So that's it!
To become better problem solvers, we need to ask better questions!

> How can we ask better questions?

In this article, we are going to explore three methodologies focused on how to ask better questions:

- IBIs Issue-Based Information System
- Theory of Constraints Thinking Process, in particular, The Current Reality Tree and the Cloud.
- TRIZ for going over contradictions


# Thinking methods

## Issue-Based Information System (IBIS)

The first methodology to ask better questions is IBIS.
In IBIs, they ask better questions by refusing to deal with a problem unless it's asked as a question.


For example, A person might say:

> I'm unhappy with my work.

According to IBIs, that is not a problem. A problem must be written in the form of a question:

> How can I be happy with my work?

or

> Why am I unhappy with my work?

or

> What makes me happy

In either case, each question is actually a problem, and we can actually propose Ideas to solve them:

### For example

``` mermaid
mindmap
	? How can I be happy at my work?
		* Ask for a rise
		* Transfer departements
		* Do the same work at a different company
	   ? What makes you happy?
		   * The outdoors
		   * Physical activity
		   * have a positive impact on society
		   * Money
```


In IBIs, there are rules on what we can write:

In IBIS, every problem is redacted as a question.
Then, below every question can only be an idea for a solution.
Or another question.
As a child to an Idea, there can only be Pros, Cons or other questions.
A Pro Con can only have as children another question.

### For example

``` mermaid
mindmap
	? what should we do about the one ring?
		* Give it to Frodo
			+ He has been carrying it already
			+ He doesn't have delusions of power
			- He is weak
			- He might fall pray to the ring as Gollum did
		* Give it to Gollum
			+ He has taken care of it for over 150 years
			+ He is invisible
		* Give it to humans
			+ Use the enemy weapon against him
			- The greed of man has failed us once before.

```


As you can see the mere constraint of having to write a problem as a question, already makes it easier to try to write options of a solution or a clarifying questions.

This is already more conducive to solving problems than just complaining.


But, sometimes we just know that we don't like the current situation, i.e. we can only complain! And express our dissatisfaction.

In that case, we can use the Current Reality Tree of the Theory of Constraints.
To bring to the surface the root problem.

## Theory of Constraints.

Ok, but how can we find the conflict?


The Current Reality Tree is TOCs method to voice the dissatisfaction that the different people have with the current situation.
Once everyone has voiced their concerns,
We can start to build cause-and-effect relationships between the concerns.
Then, one must appear as the root cause.
This root cause will frequently appear as the beginning and end of a feedback loop. (i.e., a Death spiral)

Once we find the root cause, we can write it as a conflict.
Then, we use the Cloud to try to solve it.


### The Cloud

In the theory of constraints, the tool to define a problem is called a Conflict Resolution Diagram.
But the nickname is the Cloud because once problems are properly defined, they evaporate.

In the Cloud, we start from the conflict.
I.e., Alice wants one thing, and Bob wants another.
And they simply cannot seem to be able to reach an agreement.

The next step in the Cloud is to understand the needs.

What does Alice *need* that is satisfied by her *want*
and what are Bob's *needs* that are satisfied by his *wants*

Then, we can identify the common goal. Both their needs want to be satisfied.

``` asciiflow

********************************************************
*                  ┌──────────┐        ┌─────────┐     *
*           ┌──────┼ Alice's  ◄────────┼Alice's  │     *
*           │      │ Needs    │        │Wants    │     *
*           │      └──────────┘        └─────┬───┘     *
*      ┌────▼─┐                              │         *
*      │Common│                        ┌─────▼────┐    *
*      │Goal▲ │                        │Conflict  │    *
*      └────┼─┘                        └─────▲────┘    *
*           │                                │         *
*           │                                │         *
*           │      ┌──────────┐        ┌─────┼───┐     *
*           │      │Bob's     │        │Bob's    │     *
*           └──────┼Needs    ◄┼────────┼─ants    │     *
*                  └──────────┘        └─────────┘     *
********************************************************

```

 Now, the Cloud is a super optimistic method of thinking with the following principles:

1. there is always a common goal.
 For example, if I want to go on holiday to the mountains and my wife wants to go to the beach.
 We could go our separate ways, and there wouldn't be any conflict.
 But we have the Common Goal of *spending time together*
 So we must find a *solution* that allows us to get what we need and spend time together.

 2. Only our *wants* our desires are in conflict. Never the needs.
 Again, everyone's needs are prerequisites to reach the common goal.
 So, in the Needs, there are no conflicts; they are prerequisites
 that a good solution must satisfy.

So, how do we solve a problem?

In the theory of constraints, the solution is to first:
Verify the Arrows.
I.e., the assumptions that create the relationships between concepts.
Sometimes, one of the arrows is not valid.
And we can move on.

However, more often than not, the arrows are valid.
And we must approach the conflict head-on.

In that case, we could use TRIZ to solve the conflict!!

## TRIZ

TRIZ is a Russian acronym that roughly translates to Theory of Inventive Problem Solving.
Legend has it that Genrich Artshulller studied 10,000 Russian patients.
Trying to extract the general principles that solve problems.

This led to the enunciation of the 40 principles of TRIZ
![Triz matrix](https://en.wikipedia.org/wiki/TRIZ#/media/File:40_principles_of_TRIZ_method_720dpi.jpg)

But before we can apply the 40 principles of innovation.
We must enunciate the problem as a contradiction.
A contraction is the idea of improving the solution in one dimension and making it worse in another.
But Both are needed!
The contradiction is the problem.

### Classic examples

#### Armor vs Agility::
  Ever since the knights mounted a Horse, they knew that heavier armor would protect them better.
  But making it heavier also makes the horses go slower and get tired faster.
  So this is a contradiction: we want speed but lightness.

  This problem is observed even today with Tanks and Jeeps.

  So, what solutions have been proposed to resolve this contradiction?

  For example, some thanks have "explosive" armor. That basically explode when a projectile is approaching the tank. The explosion is the protection, not the armor.

#### Area vs. Resistance

  In a boat deck we would like to have as much area as possible, to accomadate cargo, or even land a helicopter.
  But the wider we make a boat, the more friction that it will generate, and the more fuel that will be needed

  How can we have a boat that is wide above the surface but slim below it? With a catamaran.

So, that is how Triz approaches the definition of a problem. Just find the contradiction.
I.e., the attributes that you want and ask the question in terms of the contradiction.

# Leassons Learned

So, what have we learned?

In order to better solve problems, we need to:

- Ask better questions

To ask better questions, we need to:

a) Write problems and questions and

b) Find a contradiction

A contradiction is:

- When we *need* two properties at the same time, but improving one makes the other worse.

How can we find the contradiction?

- The TOC Current Reality Tree is a useful way to find the contradiction.

How can we solve the contradiction once it is found?

- With IBIS 40 principles.


<link rel="stylesheet" href="https://unpkg.com/latex.css/style.min.css" />
<style>
body.md{
	max-width:120ch; !important
}
</style>
<!-- Markdeep: --><style class="fallback">body{visibility:hidden}</style>
<script src="https://morgan3d.github.io/markdeep/latest/markdeep.min.js?" charset="utf-8"></script>
<meta charset="utf-8" emacsmode="-*- markdown -*-">


    

November 5th, 2024
By Ruben Mevy

# How to write your ideas? #

It is very common as a student, no matter what we are studying, to find it important to know how to write—not only letters but also our ideas. I have been struggling with the fact that I have to learn and write, and maybe it sounds easy in theory, but in practice, it is not as easy as it looks. But why?

**The recipe way.**
I have realized that there are many ways to express an idea that comes to mind, but we definitely always need to keep in mind that we must have order. When we think, we always think in processes. When preparing food, we think about the entire process of its preparation, from the raw ingredients to the final dish. Similarly, ideas and the way we think when writing are exactly like a recipe. We have to start from the beginning.
There are some steps to follow in order to start writing like a pro:

**Define Your Purpose**: Before you start writing, be clear about the objective of your idea. What do you want to achieve with it? Who is it aimed at? 
We need to have at least a clear idea of who we want to reach or who we want to target with our objectives. And, above all, what we want to achieve with our idea.

**Brainstorm Ideas**: Write down all the ideas that come to mind related to the topic. Don't worry about order or coherence at this stage; just let your thoughts flow.
If your idea is about dogs, just write all about them, for example; pets, toys, dog food, bones, etc. There's more than meets the eye if we start thinking.

**Organize Your Ideas**: Once you have a list of ideas, organize them into an outline or a mind map. This will help you see the overall structure of your idea and how the different points relate to each other.
Write them down in a notebook if you want, in English or Spanish. The important thing is that you see it's easier to organize them when you have them written down somewhere. It will also be easier to relate them to each other and start consolidating your main idea.

**Write a Draft**: Start writing a draft based on your outline. Don't worry about perfection at this stage; the important thing is to get your ideas down on paper.
This is the point where the real practice begins. Just write about your ideas and start to see how they take shape. It will probably look rough at first, but as you keep writing, the way you do it will get better and better.

**Review and Edit**: After writing the draft, take some time to review and edit it. Correct grammatical errors, improve coherence, and ensure your message is clear.
Read it over and over again. First and foremost, you must like what you read. If you don't, we will have to correct spelling, change words, and the syntax of our writing, perhaps several times, until it seems right to us.

**Seek Feedback**: Share your writing with someone you trust and ask for their opinion. Feedback can help you improve and polish your idea.
You should always seek a second opinion. There's no better critic than someone who doesn't conceive the idea. Look for all kinds of critiques; sometimes life is tough, and other times it's not so much. Always keep that in mind.

**Refine Your Work**: Based on the feedback received, make the necessary adjustments to improve your writing. Now, with all the steps of our recipe, we are ready to express our ideas and get the most out of them as they should be. Now, let's enjoy writing.



<style class="fallback">body{visibility:hidden}</style><script>markdeepOptions={tocStyle:'long'};</script>
<!-- Markdeep: --><script src="https://casual-effects.com/markdeep/latest/markdeep.min.js?" charset="utf-8"></script>
<meta charset="utf-8" emacsmode="-*- markdown -*-"><link rel="stylesheet" href="https://casual-effects.com/markdeep/latest/newsmag.css?">
    <!-- Author meta tag -->
    <meta name="author" content="Your Name">

    <!-- Description meta tag -->
    <meta name="description" content="newsmag description"

    <!-- Keywords meta tag -->
    <meta name="keywords" content="keyword1, keyword2, keyword3, keyword4, keyword5">

    <!-- Other common meta tags you might want to include -->
    <meta name="robots" content="index, follow">
    <meta name="language" content="English">

    <!-- Open Graph meta tags for better social media sharing -->
    <meta property="og:title" content="Your Page Title">
    <meta property="og:description" content="A brief description for social media sharing">
    <meta property="og:image" content="https://example.com/image.jpg">
    <meta property="og:url" content="https://example.com/page-url">

	<script src="https://morgan3d.github.io/include.js/include.min.js"></script>



                          **Jag.is**
	Cooperative Innovation Studio specialized in software development, devops and project management.
	We are on this for the long term with our members, our software and our customers.

We are a software development and Innovation Studio.
Specialized in high quality, long term maintenance of software products.

(insert /nav.html here)

An independent research lab exploring the future of tools for thought.
================================================================

We envision a new computer that amplifies human intelligence. A system
that helps you think more clearly, collaborate more effectively, and is
available anywhere and anytime. Though the specifics of our work
continue to evolve, everything we do is in pursuit of this vision.

Research Tracks
---------------------------------------------------------------

Our research spans a wide variety of domains from theoretical computer
science to practical user experiences. We currently have three primary
research themes.

### Malleable Software

Designing software environments where people can customize tools in the
moment to meet their unique needs.

### Programmable Ink

Discovering a dynamic medium for sketching ideas where adding behaviors
and interaction is as natural as applying ink to paper.

### [Local-First](/local-first)

Exploring software architecture that returns data to users and enables
collaboration in every tool.


Our Writing
==============================================================

This are the innovations that have been ocupaying our minds lately


### [2024-11-07: posts/ideas](./posts/ideas).
[lab notes ongaing](./posts/ideas)


### [2024-11-07: posts/how_to_define_a_problem](./posts/how_to_define_a_problem).
[lab notes ongaing](./posts/how_to_define_a_problem)


### [2024-11-07: posts/faust_a_musical_dsl](./posts/faust_a_musical_dsl).
[lab notes ongaing](./posts/faust_a_musical_dsl)


### [2024-11-07: posts/a_dozen_problems](./posts/a_dozen_problems).
[lab notes ongaing](./posts/a_dozen_problems)


### [2024-11-07: posts/Unlocking_the_Power_of_Personal_Cloud](./posts/Unlocking_the_Power_of_Personal_Cloud).
[lab notes ongaing](./posts/Unlocking_the_Power_of_Personal_Cloud)


### [2024-11-07: posts/Understanding_complexity_in_software_systems](./posts/Understanding_complexity_in_software_systems).
[lab notes ongaing](./posts/Understanding_complexity_in_software_systems)


### [2024-11-07: posts/The_Rise_and_Fall_of_Abacus_Rationale](./posts/The_Rise_and_Fall_of_Abacus_Rationale).
[lab notes ongaing](./posts/The_Rise_and_Fall_of_Abacus_Rationale)


### [2024-11-07: posts/Terravision_vs_Google_Earth](./posts/Terravision_vs_Google_Earth).
[lab notes ongaing](./posts/Terravision_vs_Google_Earth)


### [2024-11-07: posts/Single_text_file](./posts/Single_text_file).
[lab notes ongaing](./posts/Single_text_file)


### [2024-11-07: posts/Requirements_in_the_Age_of_AI](./posts/Requirements_in_the_Age_of_AI).
[lab notes ongaing](./posts/Requirements_in_the_Age_of_AI)


### [2024-11-07: posts/Psychological_Safety](./posts/Psychological_Safety).
[lab notes ongaing](./posts/Psychological_Safety)


### [2024-11-07: posts/PMI_vs_Flight_Levels_Less_is_More](./posts/PMI_vs_Flight_Levels_Less_is_More).
[lab notes ongaing](./posts/PMI_vs_Flight_Levels_Less_is_More)


### [2024-11-07: posts/Navigating_GHC_compilation_errors_in_Emacs](./posts/Navigating_GHC_compilation_errors_in_Emacs).
[lab notes ongaing](./posts/Navigating_GHC_compilation_errors_in_Emacs)


### [2024-11-07: posts/Multi-layered_Proxy_Architecture_for_my_Personal_Cloud](./posts/Multi-layered_Proxy_Architecture_for_my_Personal_Cloud).
[lab notes ongaing](./posts/Multi-layered_Proxy_Architecture_for_my_Personal_Cloud)


### [2024-11-07: posts/Manage_complexity_behind_simple_interfaces](./posts/Manage_complexity_behind_simple_interfaces).
[lab notes ongaing](./posts/Manage_complexity_behind_simple_interfaces)


### [2024-11-07: posts/Kanban_Serious_Games_Intro](./posts/Kanban_Serious_Games_Intro).
[lab notes ongaing](./posts/Kanban_Serious_Games_Intro)


### [2024-11-07: posts/Kanban_Case_Study_in_Public_Sector_Part_I](./posts/Kanban_Case_Study_in_Public_Sector_Part_I).
[lab notes ongaing](./posts/Kanban_Case_Study_in_Public_Sector_Part_I)


### [2024-11-07: posts/Extending_the_Power_of_your_Personal_Cloud](./posts/Extending_the_Power_of_your_Personal_Cloud).
[lab notes ongaing](./posts/Extending_the_Power_of_your_Personal_Cloud)


### [2024-11-07: posts/Did_You_Read_This_Book](./posts/Did_You_Read_This_Book).
[lab notes ongaing](./posts/Did_You_Read_This_Book)


### [2024-11-07: posts/Devtron_Enhancing_Kubernetes_Management_and_DevOps_Pipelines](./posts/Devtron_Enhancing_Kubernetes_Management_and_DevOps_Pipelines).
[lab notes ongaing](./posts/Devtron_Enhancing_Kubernetes_Management_and_DevOps_Pipelines)


### [2024-11-07: posts/Declarative_dotfiles_with_Home_Manager](./posts/Declarative_dotfiles_with_Home_Manager).
[lab notes ongaing](./posts/Declarative_dotfiles_with_Home_Manager)


### [2024-11-07: posts/Creating_a_QR_for_Google_review_URL](./posts/Creating_a_QR_for_Google_review_URL).
[lab notes ongaing](./posts/Creating_a_QR_for_Google_review_URL)


### [2024-11-07: posts/Create_Abundance_With_Software](./posts/Create_Abundance_With_Software).
[lab notes ongaing](./posts/Create_Abundance_With_Software)


### [2024-11-07: posts/Bloom_Taxonomy_Shu_Ha_Ri_Expertise](./posts/Bloom_Taxonomy_Shu_Ha_Ri_Expertise).
[lab notes ongaing](./posts/Bloom_Taxonomy_Shu_Ha_Ri_Expertise)


### [2024-11-07: posts/A_Tool_in_a_World_Full_of_Distractions](./posts/A_Tool_in_a_World_Full_of_Distractions).
[lab notes ongaing](./posts/A_Tool_in_a_World_Full_of_Distractions)


### [2024-11-07: posts/A_Real_Challenge_as_DevOps_Navigating_Key_Hurdles_and_Solutions](./posts/A_Real_Challenge_as_DevOps_Navigating_Key_Hurdles_and_Solutions).
[lab notes ongaing](./posts/A_Real_Challenge_as_DevOps_Navigating_Key_Hurdles_and_Solutions)


--------------------------------------------------

#### Connect with us

Say <hello@jag.is>

Code on [Github](https://github.com/jagcoop)

#### Our news letter

Keep up-to-date with the lab's latest findings, appearances, and
happenings by subscribing to our newsletter. For a sneak peek, [browse
the archive](/newsletter).

Email

<ul>
    <li><a href="/">index</a></li>
		<li>[posts/ideas](/posts/ideas/index.html)</li>
		<li>[posts/how_to_define_a_problem](/posts/how_to_define_a_problem/index.html)</li>
		<li>[posts/faust_a_musical_dsl](/posts/faust_a_musical_dsl/index.html)</li>
		<li>[posts/a_dozen_problems](/posts/a_dozen_problems/index.html)</li>
		<li>[posts/Unlocking_the_Power_of_Personal_Cloud](/posts/Unlocking_the_Power_of_Personal_Cloud/index.html)</li>
		<li>[posts/Understanding_complexity_in_software_systems](/posts/Understanding_complexity_in_software_systems/index.html)</li>
		<li>[posts/The_Rise_and_Fall_of_Abacus_Rationale](/posts/The_Rise_and_Fall_of_Abacus_Rationale/index.html)</li>
		<li>[posts/Terravision_vs_Google_Earth](/posts/Terravision_vs_Google_Earth/index.html)</li>
		<li>[posts/Single_text_file](/posts/Single_text_file/index.html)</li>
		<li>[posts/Requirements_in_the_Age_of_AI](/posts/Requirements_in_the_Age_of_AI/index.html)</li>
		<li>[posts/Psychological_Safety](/posts/Psychological_Safety/index.html)</li>
		<li>[posts/PMI_vs_Flight_Levels_Less_is_More](/posts/PMI_vs_Flight_Levels_Less_is_More/index.html)</li>
		<li>[posts/Navigating_GHC_compilation_errors_in_Emacs](/posts/Navigating_GHC_compilation_errors_in_Emacs/index.html)</li>
		<li>[posts/Multi-layered_Proxy_Architecture_for_my_Personal_Cloud](/posts/Multi-layered_Proxy_Architecture_for_my_Personal_Cloud/index.html)</li>
		<li>[posts/Manage_complexity_behind_simple_interfaces](/posts/Manage_complexity_behind_simple_interfaces/index.html)</li>
		<li>[posts/Kanban_Serious_Games_Intro](/posts/Kanban_Serious_Games_Intro/index.html)</li>
		<li>[posts/Kanban_Case_Study_in_Public_Sector_Part_I](/posts/Kanban_Case_Study_in_Public_Sector_Part_I/index.html)</li>
		<li>[posts/Extending_the_Power_of_your_Personal_Cloud](/posts/Extending_the_Power_of_your_Personal_Cloud/index.html)</li>
		<li>[posts/Did_You_Read_This_Book](/posts/Did_You_Read_This_Book/index.html)</li>
		<li>[posts/Devtron_Enhancing_Kubernetes_Management_and_DevOps_Pipelines](/posts/Devtron_Enhancing_Kubernetes_Management_and_DevOps_Pipelines/index.html)</li>
		<li>[posts/Declarative_dotfiles_with_Home_Manager](/posts/Declarative_dotfiles_with_Home_Manager/index.html)</li>
		<li>[posts/Creating_a_QR_for_Google_review_URL](/posts/Creating_a_QR_for_Google_review_URL/index.html)</li>
		<li>[posts/Create_Abundance_With_Software](/posts/Create_Abundance_With_Software/index.html)</li>
		<li>[posts/Bloom_Taxonomy_Shu_Ha_Ri_Expertise](/posts/Bloom_Taxonomy_Shu_Ha_Ri_Expertise/index.html)</li>
		<li>[posts/A_Tool_in_a_World_Full_of_Distractions](/posts/A_Tool_in_a_World_Full_of_Distractions/index.html)</li>
		<li>[posts/A_Real_Challenge_as_DevOps_Navigating_Key_Hurdles_and_Solutions](/posts/A_Real_Challenge_as_DevOps_Navigating_Key_Hurdles_and_Solutions/index.html)</li>
</ul>

<script src="https://casual-effects.com/markdeep/latest/markdeep.min.js?" charset="utf-8"></script>

--------------------------------------------------

CC-By-Sa-NC JagIs

<style class="fallback">body{visibility:hidden}</style><script>markdeepOptions={tocStyle:'medium'};</script>
<!-- Markdeep: --><script src="https://casual-effects.com/markdeep/latest/markdeep.min.js?" charset="utf-8"></script>
<meta charset="utf-8" emacsmode="-*- markdown -*-">

<meta name="author" content="Alejandro Garcia Fernandez">
<meta name="description" content="Implementing the Architecture Oriented Programming of Objective.st in Eiffel">
<meta name="keywords" content="Eiffel, Objective Smalltalk, Design Patterns">
<meta name="robots" content="index, follow">
<meta name="language" content="English">


                  **Architecture-Oriented Programming in Eiffel**
	Applying systems architecture (i.e. between servers) at level of programs (i.e. between functions)


A Conjecture
===============================================================================

Architecture Oriented Programming (AOP) is a programming paradigm that increases reusability and modularity of Object Oriented Languages.
By identifying patterns found at the *architecture level* of *systems* and shrinking them at the *code level* of *programs*.
The advanced features of Eiffel, such as Genericity, Aliasing, and Design by Contract, make it an ideal environment to implement AOP.
And it would result in smaller code with more reusability in Eiffel programs.

Background
================================================================================

Architecture Oriented Programming (AOP) is the name given by Weiher and Hirschfeld to their ideas in developing the Objective Smalltalk language.
The main idea is delightfully simple:

>  What if we took inspiration from the architecture of big systems,
>    and shrink the techniques to organize a single program.

(Weiher, 2020 a)  identified the first patterns and also made a summary in the YouTube presentation: "Can programmers escape the gentle tyranny of call return" (Weiher, 2020 b)
Also, each pattern was published independently. As is shown in table [Summary]:

| Inspired by                      | AOP Proposes                          | One Sentence Summary                                                                                                                                                                                 | Examples                                                                                                                                                     | Reference                                                                                                     |
|----------------------------------|---------------------------------------|------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|--------------------------------------------------------------------------------------------------------------------------------------------------------------|---------------------------------------------------------------------------------------------------------------|
| Internet URLs and URIs           | Polymorphic identifiers               | If every resource on your program: variables, objects, files, APIs had a local URI that you can use to communicate with it.                                                                          | var:person/name var:person/{attribute},     file://tmp/button.png ,    http://www.example.com/button.png, file:{env:HOME}/rfcs/{rfcName}                     | Weiher, M., & Hirschfeld, R. (2013). Polymorphic identifiers: uniform resource access in objective-smalltalk. |
| Internet Protocols FTP, WWW, IRC | Schemes                               | The same way that a URI like ftp://myDir/myImage.jpg has a different behavior, than www://myDy/myImage.jpg. Schemes change the behavior that Polymorphic URI will have                               |                                                                                                                                                              | Weiher, M., & Hirschfeld, R. (2013). Polymorphic identifiers: uniform resource access in objective-smalltalk. |
| Spreadsheet formulas             | References                            | The same way that changing a value in a cell in a spreadsheet automatically recalculates the derived values. Reference values will automatically update the derived values in a uniform identifier. |                                                                                                                                                              | Weiher, M., & Hirschfeld, R. (2013). Polymorphic identifiers: uniform resource access in objective-smalltalk. |
| Unix pipes and filters           | Polymorphic write streams             | What if unix pipes, instead of sending a chain of text to the next process, threw a nested object structure                                                                                           |                                                                                                                                                              | Weiher, M., & Hirschfeld, R. (2019). Standard object out: streaming objects with polymorphic write streams.   |
| Rest and stackable filesystems   | Storage combinators                   | With limited API verbs (like REST) you can create components that can compose, web servers combined with cache servers and load balancers.                                                           | A composition serving the files in $HOME/Sites, cached by memory. server := ref:file:{env:HOME} -> CachingStore -> SchemeHTTPServer port:8080. server start. | Weiher, M., & Hirschfeld, R. (2019). Storage combinators.                                                     |
| Constraint programming           | Constraints as polymorphic connectors | What if the assignment operation had more meaning, such as keeping the values unidirectionally updated or synchronized?                                                                              |                                                                                                                                                              | Weiher, M., & Hirschfeld, R. (2016). Constraints as polymorphic connectors.                                   |
[Table [Summary]: Summary of AOP Patterns and their publication]

Uncertainties (Known-Unknowns)
================================================================================

In his conference, Marcel P. Weiher says that the comments for Unicon made it decide to create a new language (Objective Smalltalk) instead of a library for an existing language.
And on this project, I'm doing exactly that: creating a library, not a new language.
So it might be a bad idea.
However, the advanced tools of Eiffel make this a better approach in this language.

My plan
================================================================================

To get the implementation of AOP in the Eiffel, I intend to:

First
-----------

Write a complete design by contract specification of the architecture patterns identified.
This will require also the description of frame rules.
Probably using "model queries" (Polikarpova et al. 2012)

Second
-----------

I'll make several implementations.
Here, I'll experiment.
Where I'd ask a set of 5 developers to each
develop their storage combinator and polymorphic identifier.
Then, I will try to compose all of them.
And survey the developers to see how they feel about the patterns' specification and composability.

Third
-----------

To test that the code based on AOP is more reusable than the current call return style. I will reimplement a project in Eiffel (like the Nino Webserver).
On AOP and measure using Avontis & Mingis 93 "Metrics from Object-Oriented Design."


Future work (avenues to explore)
=============================================================================

It seems pretentious to talk about "future work" when discussing a proposal for a future project.
But, assuming that I can achieve the goals in the plan. I.e., a specification and implementation for AOP in Eiffel.
What other avenues will open for exploration?
At the moment, I can imagine the following:

Shrink other architectural patterns at the level of programs
-----------------------------------------------------------------------------
Weiher has currently only identified six architectural patterns and shrunk them to the level of programs.
So, a natural progression of this work would be to specify and code even more patterns.

For example, how would a queue-based architecture (like Rabbit MQ) look at the program level? Something like Erlang with OTP?

How would an Event Sourcing architecture look at the program level?
Could we reuse the agent and pub/sub mechanism in GUI Eiffel for other object communication, not only GUI?
Reusing it as the main means of communication among objects.


Given a specification, can ChatGPT program an implementation?
-----------------------------------------------------------------------------
If we follow the headlines, there are two ways of thinking about programming and Large Language Models (LLMs like chatgpt).
Either:

> Programming is dead, and ChatGPT killed it.

or

> ChatGPT and their inherent hallucinations make it irrelevant to programming.

However, I think Design by Contract (DBC) opens an avenue for collaboration between the two approaches.
In this collaboration, humans would write a specification in DBC  with the appropriate frame rules.
Then ChatGPT would try to code to the specification.

So it would be fascinating to see if, given a spec for AOP, we could get ChatGPT to implement it.

Others
-----------------------------
While developing this work, other avenues of growth will become more apparent.


Expected Contributions
================================================================================

As a result of this work, I expect to deliver the following work products.

- Write a design by contract specification of the AOP patterns documented by Weiher.
- Program an Eiffel implementation of said patterns.
- Share the specification and its benefits with the academic and development communities so they can use AOP.

References
================================================================================

- Avotins, J., & Mingins, C. (1993). Metrics for Object-Oriented Design. International Conference on Software Technology: Methods and Tools.
- Polikarpova, N., Furia, C.A., Pei, Y., Wei, Y., & Meyer, B. (2012). What good are strong specifications? 2013 35th International Conference on Software Engineering (ICSE), 262-271.
- Weiher, M., & Hirschfeld, R. (2013). Polymorphic identifiers: uniform resource access in objective-smalltalk. Dynamic Languages Symposium.
- Weiher, M., & Hirschfeld, R. (2016). Constraints as polymorphic connectors. Proceedings of the 15th International Conference on Modularity.
- Weiher, M., & Hirschfeld, R. (2019). Standard object out: streaming objects with polymorphic write streams. Proceedings of the 15th ACM SIGPLAN International Symposium on Dynamic Languages.
- Weiher, M., & Hirschfeld, R. (2019). Storage combinators. Proceedings of the 2019 ACM SIGPLAN International Symposium on New Ideas, New Paradigms, and Reflections on Programming and Software.
- Weiher, M. (2020 a). Can programmers escape the gentle tyranny of call/return? Companion Proceedings of the 4th International Conference on Art, Science, and Engineering of Programming.
- Weiher, M. (2020 b). Can programmers escape the gentle tyranny of call/return? https://www.youtube.com/watch?v=Gel8ffr4pqw


<link rel="stylesheet" href="https://unpkg.com/latex.css/style.min.css" />
<style>
body.md{
	max-width:90ch; !important
}
</style>
<!-- Markdeep: --><style class="fallback">body{visibility:hidden}</style>
<script src="https://morgan3d.github.io/markdeep/latest/markdeep.min.js?" charset="utf-8"></script>
<meta charset="utf-8" emacsmode="-*- markdown -*-"><link rel="stylesheet" href="https://casual-effects.com/markdeep/latest/newsmag.css?">
    <!-- Author meta tag -->
    <meta name="author" content="Your Name">

    <!-- Description meta tag -->
    <meta name="description" content="newsmag description"

    <!-- Keywords meta tag -->
    <meta name="keywords" content="keyword1, keyword2, keyword3, keyword4, keyword5">

    <!-- Other common meta tags you might want to include -->
    <meta name="robots" content="index, follow">
    <meta name="language" content="English">

    <!-- Open Graph meta tags for better social media sharing -->
    <meta property="og:title" content="Your Page Title">
    <meta property="og:description" content="A brief description for social media sharing">
    <meta property="og:image" content="https://example.com/image.jpg">
    <meta property="og:url" content="https://example.com/page-url">

	<script src="https://morgan3d.github.io/include.js/include.min.js"></script>



                          **Jag.is**
	Cooperative Innovation Studio specialized in software development, devops and project management.
	We are on this for the long term with our members, our software and our customers.

We are a software development and Innovation Studio.
Specialized in high quality, long term maintenance of software products.

(insert /nav.html here)

An independent research lab exploring the future of tools for thought.
================================================================

We envision a new computer that amplifies human intelligence. A system
that helps you think more clearly, collaborate more effectively, and is
available anywhere and anytime. Though the specifics of our work
continue to evolve, everything we do is in pursuit of this vision.

Research Tracks
---------------------------------------------------------------

Our research spans a wide variety of domains from theoretical computer
science to practical user experiences. We currently have three primary
research themes.

### Malleable Software

Designing software environments where people can customize tools in the
moment to meet their unique needs.

### Programmable Ink

Discovering a dynamic medium for sketching ideas where adding behaviors
and interaction is as natural as applying ink to paper.

### [Local-First](/local-first)

Exploring software architecture that returns data to users and enables
collaboration in every tool.


Our Writing
==============================================================

This are the innovations that have been ocupaying our minds lately


### [2024-11-07: projects/rewards.codes](./projects/rewards.codes).
[lab notes ongaing](./projects/rewards.codes)


### [2024-11-07: projects/AOP_in_Eiffel](./projects/AOP_in_Eiffel).
[lab notes ongaing](./projects/AOP_in_Eiffel)


--------------------------------------------------

#### Connect with us

Say <hello@jag.is>

Code on [Github](https://github.com/jagcoop)

#### Our news letter

Keep up-to-date with the lab's latest findings, appearances, and
happenings by subscribing to our newsletter. For a sneak peek, [browse
the archive](/newsletter).

Email

<ul>
    <li><a href="/">index</a></li>
		<li>[projects/rewards.codes](/projects/rewards.codes/index.html)</li>
		<li>[projects/AOP_in_Eiffel](/projects/AOP_in_Eiffel/index.html)</li>
</ul>

<script src="https://casual-effects.com/markdeep/latest/markdeep.min.js?" charset="utf-8"></script>

--------------------------------------------------

CC-By-Sa-NC JagIs

<style class="fallback">body{visibility:hidden}</style><script>markdeepOptions={tocStyle:'medium'};</script>
<!-- Markdeep: --><script src="https://casual-effects.com/markdeep/latest/markdeep.min.js?" charset="utf-8"></script>
   <meta charset="utf-8" emacsmode="-*- markdown -*-"> <link rel="stylesheet" href="https://casual-effects.com/markdeep/latest/journal.css?">

                        **Rewards Codes**
                        A Simple Loyalty Platform for *Small* Businesses Using **Big** Strategies


[Rewards Codes - RwC](https://rewards.codes)
Rewards Codes is a straightforward loyalty platform designed to help small businesses implement big strategies for customer retention. This project evolved from a previous initiative, "SigueMS," which was an SMS interface for Twitter.

Why do 50% of loyalty strategies fail? Mainly because they are:

1. Hard to use,
2. Hard to understand, and
3. Offer unappealing rewards.

Rewards Codes addresses these challenges by adopting best practices from the retail and service industries. We focus on:

* Simplicity: With just two easy steps, our platform is designed to be intuitive and user-friendly.
* Accessibility: We use globally recognized communication platforms, making it easy for businesses and customers to engage.
* Valuable Rewards: By allowing businesses to exchange reward points within our network, customers always have access to appealing, desirable rewards.

Thanks to the support of our clients, Rewards Codes has become a tool for fostering positive communication between businesses and their customers. It’s fascinating how an initial customer visit can grow into an ongoing dialogue that includes service feedback, repeat purchases, product launches, and even quick answers to frequently asked questions. Ultimately, this leads to stronger, more meaningful relationships.

### What’s Next for Rewards Codes?

We’re continually evolving to meet the needs of small businesses. Our next steps include expanding the network of businesses that can exchange rewards, introducing new customer engagement features like creating and updating appointments and orders automatically, and exploring partnerships with additional communication platforms. Our goal is to make it even easier for businesses to connect with their customers, strengthen loyalty, and drive growth.

2024-09-19: Features Roadmap 
=================================================================


************************************************************************************
*                  ┌──────────────────────────────────┐ ┌─────────────────────────┐*
*                  │                                  │ │                         │*
*                  │        Q4 2024                   │ │       Q1 2025           │*
*                  │                                  │ │                         │*
*                  │                                  │ │                         │*
*                  │                                  │ │                         │*
*                  └──────────────────────────────────┘ └─────────────────────────┘*
*┌────────────────┐                                                                *
*│                │  * Visits loyalty program             * Customization 1.1      *
*│  Platform      │  * Static QR                                                   *
*│                │  * Dynamic QR                                                  *
*└────────────────┘  * Customization 1.0                                           *
*                                                                                  *
*┌────────────────┐                                                                *
*│                │  * Odoo                               * Oxxo Pay               *
*│  Integrations  │  * Whatsapp reminders                                          *
*│                │  * Whatsapp device link                                        *
*└────────────────┘                                                                *
*                                                                                  *
*┌────────────────┐                                                                *
*│                │  * Company Loyalty card                                        *
*│   Apps         │  * Redeem Code                                                 *
*│                │  * Nearby RwC Businesses (Map)                                 *
*└────────────────┘                                                                *
*                                                                                  *
*┌────────────────┐                                                                *
*│                │  * Customized virtual assistant       * Historical context     *
*│   Chatbot      │  * Time for response customization    * User context           *
*│                │                                       * Agenda management      *
*└────────────────┘                                                                *
************************************************************************************

2024-10-15: Simple architecture 
=================================================================

# Architecture Overview:

Our system architecture revolves around two primary microservices, each serving a crucial function:

Rewards Microservice: This microservice handles the core functionality of giving and redeeming rewards, retrieving balance and account information, and managing overall rewards activity for businesses.

Messaging & Notifications Microservice: This service manages all the interactions between businesses and their customers, including messages and notifications, ensuring smooth and timely communication.

At the center of these microservices is an API Gateway, which provides controlled access to them. This gateway allows external applications to interact with the services securely and efficiently.

For data storage, we employ a Graph Database to record and analyze all customer-business interactions. The use of a graph structure helps us map relationships between customers, businesses, and rewards in a flexible and scalable way.

## Recent Addition: Chatbot Module

We've recently expanded the architecture by integrating a Chatbot Module. Initially, the main microservice interacted with an external service to handle business context exclusively. However, recognizing the need for more meaningful conversations, we are developing additional endpoints to incorporate user context alongside business information.

This enhancement allows the chatbot to provide more personalized, relevant responses, making the platform even more engaging for customers.

## User Context Module

To enrich the chatbot's ability to interact with users meaningfully, we are implementing a User Context Module, which works through two complementary bots:

Classifier Bot: This bot's role is to determine whether a prompt requires querying the database for specific user data or if it can be answered using only business context. This first step ensures that the system responds efficiently by directing the query to the correct source.

Context Bot: Once the Classifier Bot identifies the need for user data, the Context Bot generates the necessary queries to fetch that data. It then supplies this additional user context to the chatbot, allowing it to return an enriched response with deeper insights.

By utilizing these two bots together, the system can deliver more personalized interactions, improving the user experience and fostering stronger connections between businesses and their customers.

*************************************************************************************************************************************************************************************
*                                                                                                                                                                                   *
*                 ┌─────────────┐                                                                                                                                                   *
*                 │  Business   │                                                                                                                                                   *
*                 │  Context    │                                                                                                                                                   *
*                 └─────────────┘──┐  User context                                                                                                                                  *
*     ┌─────────────►│             ◄───────────┐                                                                                                                                    *
*     │              │  Classifier │           │                                                                                                                                    *
*     │         ┌────┼    Bot     ─┼──────┐    │                                                                                                                                    *
*  prompt       │    └─────────────┘      │    │                                                                                                                                    *
*     │         │                         │    │                                                                                                                                    *
*     │      Answer                       │    │                                                                                                                                    *
*     │         │                         │    │                                                                                                                                    *
*   ┌─┼─────────▼┐        Query        ┌──▼────┼───┐                                                                                                                                *
*   │            │      ┌──────────────┼           │                                                                                                                                *
*   │   User     │      │              │  Context  │                                                                                                                                *
*   │            │      │     ┌────────►    Bot    │                                                                                                                                *
*   └────────────┘      │     │ Result └───────────┘                                                                                                                                *
*                       │     │                                                                                                                                                     *
*                     ┌─▼─────┼───┐                                                                                                                                                 *
*                     │ Rewards   │                                                                                                                                                 *
*                     │  Service  │                                                                                                                                                 *
*                     └─┬──────▲──┘                                                                                                                                                 *
*                       │      │ Result ┌────────┐                                                                                                                                  *
*                       │      └────────┼        │                                                                                                                                  *
*                       │               │  DB    │                                                                                                                                  *
*                       └───────────────►        │                                                                                                                                  *
*                        Execute query  └────────┘                                                                                                                                  *
*                                                                                                                                                                                   *
*                                                                                                                                                                                   *
*                                                                                                                                                                                   *
*************************************************************************************************************************************************************************************

### Real-Life Example:

Here’s how the system works in a real-world scenario:

A user asks the chatbot for a recommendation for a place to have dinner. Initially, the chatbot (powered by the Classifier Bot) determines that it needs more than just general business information to give a personalized suggestion. The Classifier Bot recognizes that the best way to provide an accurate recommendation is by considering the user's past preferences.

The system creates a query that checks if the user has previously visited and liked any restaurants within the network of businesses. After executing the query, the chatbot retrieves a list of restaurants the user enjoyed in the past.

Additionally, using data stored in the Graph Database, the Context Bot also identifies similar businesses that other users have liked, which match the user's previous preferences. With this information, the chatbot responds with a personalized dinner recommendation, tailored not only to the user's history but also suggesting similar options based on other users' preferences.

This process ensures the response feels highly personalized, increasing the chances of the user being satisfied with the recommendation, and strengthening their loyalty to the businesses in the network.

<style class="fallback">body{visibility:hidden}</style><script>markdeepOptions={tocStyle:'long'};</script>
<!-- Markdeep: --><script src="https://casual-effects.com/markdeep/latest/markdeep.min.js?" charset="utf-8"></script>
<li>[.](././) 
    <ul>
	  <li>[./projects](././projects/) 
	      <ul>
	  	  <li>[./projects/rewards.codes](././projects/rewards.codes/) 
	  	  </li>
	  	</ul>
	      <ul>
	  	  <li>[./projects/AOP_in_Eiffel](././projects/AOP_in_Eiffel/) 
	  	  </li>
	  	</ul>
	  </li>
	</ul>
    <ul>
	  <li>[./posts](././posts/) 
	      <ul>
	  	  <li>[./posts/ideas](././posts/ideas/) 
	  	  </li>
	  	</ul>
	      <ul>
	  	  <li>[./posts/how_to_define_a_problem](././posts/how_to_define_a_problem/) 
	  	  </li>
	  	</ul>
	      <ul>
	  	  <li>[./posts/faust_a_musical_dsl](././posts/faust_a_musical_dsl/) 
	  	  </li>
	  	</ul>
	      <ul>
	  	  <li>[./posts/a_dozen_problems](././posts/a_dozen_problems/) 
	  	  </li>
	  	</ul>
	      <ul>
	  	  <li>[./posts/Unlocking_the_Power_of_Personal_Cloud](././posts/Unlocking_the_Power_of_Personal_Cloud/) 
	  	  </li>
	  	</ul>
	      <ul>
	  	  <li>[./posts/Understanding_complexity_in_software_systems](././posts/Understanding_complexity_in_software_systems/) 
	  	  </li>
	  	</ul>
	      <ul>
	  	  <li>[./posts/The_Rise_and_Fall_of_Abacus_Rationale](././posts/The_Rise_and_Fall_of_Abacus_Rationale/) 
	  	  </li>
	  	</ul>
	      <ul>
	  	  <li>[./posts/Terravision_vs_Google_Earth](././posts/Terravision_vs_Google_Earth/) 
	  	  </li>
	  	</ul>
	      <ul>
	  	  <li>[./posts/Single_text_file](././posts/Single_text_file/) 
	  	  </li>
	  	</ul>
	      <ul>
	  	  <li>[./posts/Requirements_in_the_Age_of_AI](././posts/Requirements_in_the_Age_of_AI/) 
	  	  </li>
	  	</ul>
	      <ul>
	  	  <li>[./posts/Psychological_Safety](././posts/Psychological_Safety/) 
	  	  </li>
	  	</ul>
	      <ul>
	  	  <li>[./posts/PMI_vs_Flight_Levels_Less_is_More](././posts/PMI_vs_Flight_Levels_Less_is_More/) 
	  	  </li>
	  	</ul>
	      <ul>
	  	  <li>[./posts/Navigating_GHC_compilation_errors_in_Emacs](././posts/Navigating_GHC_compilation_errors_in_Emacs/) 
	  	  </li>
	  	</ul>
	      <ul>
	  	  <li>[./posts/Multi-layered_Proxy_Architecture_for_my_Personal_Cloud](././posts/Multi-layered_Proxy_Architecture_for_my_Personal_Cloud/) 
	  	  </li>
	  	</ul>
	      <ul>
	  	  <li>[./posts/Manage_complexity_behind_simple_interfaces](././posts/Manage_complexity_behind_simple_interfaces/) 
	  	  </li>
	  	</ul>
	      <ul>
	  	  <li>[./posts/Kanban_Serious_Games_Intro](././posts/Kanban_Serious_Games_Intro/) 
	  	  </li>
	  	</ul>
	      <ul>
	  	  <li>[./posts/Kanban_Case_Study_in_Public_Sector_Part_I](././posts/Kanban_Case_Study_in_Public_Sector_Part_I/) 
	  	  </li>
	  	</ul>
	      <ul>
	  	  <li>[./posts/Extending_the_Power_of_your_Personal_Cloud](././posts/Extending_the_Power_of_your_Personal_Cloud/) 
	  	  </li>
	  	</ul>
	      <ul>
	  	  <li>[./posts/Did_You_Read_This_Book](././posts/Did_You_Read_This_Book/) 
	  	  </li>
	  	</ul>
	      <ul>
	  	  <li>[./posts/Devtron_Enhancing_Kubernetes_Management_and_DevOps_Pipelines](././posts/Devtron_Enhancing_Kubernetes_Management_and_DevOps_Pipelines/) 
	  	  </li>
	  	</ul>
	      <ul>
	  	  <li>[./posts/Declarative_dotfiles_with_Home_Manager](././posts/Declarative_dotfiles_with_Home_Manager/) 
	  	  </li>
	  	</ul>
	      <ul>
	  	  <li>[./posts/Creating_a_QR_for_Google_review_URL](././posts/Creating_a_QR_for_Google_review_URL/) 
	  	  </li>
	  	</ul>
	      <ul>
	  	  <li>[./posts/Create_Abundance_With_Software](././posts/Create_Abundance_With_Software/) 
	  	  </li>
	  	</ul>
	      <ul>
	  	  <li>[./posts/Bloom_Taxonomy_Shu_Ha_Ri_Expertise](././posts/Bloom_Taxonomy_Shu_Ha_Ri_Expertise/) 
	  	  </li>
	  	</ul>
	      <ul>
	  	  <li>[./posts/A_Tool_in_a_World_Full_of_Distractions](././posts/A_Tool_in_a_World_Full_of_Distractions/) 
	  	  </li>
	  	</ul>
	      <ul>
	  	  <li>[./posts/A_Real_Challenge_as_DevOps_Navigating_Key_Hurdles_and_Solutions](././posts/A_Real_Challenge_as_DevOps_Navigating_Key_Hurdles_and_Solutions/) 
	  	  </li>
	  	</ul>
	  </li>
	</ul>
    <ul>
	  <li>[./about](././about/) 
	  </li>
	</ul>
</li>
